
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Deep Neural Networks: Bridging Parametric and Non-Parametric Models &#8212; Mathematics for Machine Learning</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapter_spaces/nn_parametric_nonparametrix';</script>
    <link rel="canonical" href="https://healthml.github.io/Math4ML/chapter_spaces/nn_parametric_nonparametrix.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/hpi-logo-colored.svg" class="logo__image only-light" alt="Mathematics for Machine Learning - Home"/>
    <script>document.write(`<img src="../_static/hpi-logo-colored.svg" class="logo__image only-dark" alt="Mathematics for Machine Learning - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    Preface
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Mathematics for Machine Learning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_ml_basics/intro.html">Overview of Machine Learning Concepts</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_ml_basics/classification.html">Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_ml_basics/regression.html">Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_ml_basics/clustering.html">Clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_ml_basics/representation_learning.html">Representation Learning</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="overview_spaces.html">Vectors, Functions and the Spaces they live in</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="vector_spaces.html">Vector spaces</a></li>
<li class="toctree-l2"><a class="reference internal" href="polynomial_vector_space.html">Polynomials</a></li>
<li class="toctree-l2"><a class="reference internal" href="basis_functions_vector_space.html">Basis Functions Form a Vector Space</a></li>
<li class="toctree-l2"><a class="reference internal" href="subspaces.html">Subspaces</a></li>
<li class="toctree-l2"><a class="reference internal" href="metric_spaces.html">Metric spaces</a></li>

<li class="toctree-l2"><a class="reference internal" href="normed_spaces.html">Normed spaces</a></li>
<li class="toctree-l2"><a class="reference internal" href="inner_product_spaces.html">Inner product spaces</a></li>
<li class="toctree-l2"><a class="reference internal" href="transposition.html">Transposition</a></li>

</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_calculus/overview_calculus.html">Multivariate Calculus in Machine Learning</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_calculus/extrema.html">Extrema</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_calculus/gradients.html">Gradients and the Gradient Descent Algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_calculus/jacobian.html">The Jacobian</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_calculus/chain_rule.html">The chain rule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_calculus/hessian.html">The Hessian</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendix</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../appendix/proofs.html">Detailed Proofs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendix/differentiation_rules.html">Differentiation Rules</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/HealthML/Math4ML" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/HealthML/Math4ML/edit/main/book/chapter_spaces/nn_parametric_nonparametrix.md" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/HealthML/Math4ML/issues/new?title=Issue%20on%20page%20%2Fchapter_spaces/nn_parametric_nonparametrix.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/chapter_spaces/nn_parametric_nonparametrix.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Deep Neural Networks: Bridging Parametric and Non-Parametric Models</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Deep Neural Networks: Bridging Parametric and Non-Parametric Models</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#why-do-we-place-priors-on-weights-instead-of-functions">Why Do We Place Priors on Weights Instead of Functions?</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#in-summary">In Summary</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#sgd-as-a-stochastic-process">1. SGD as a Stochastic Process</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#stationary-distribution-around-an-optimum">2. Stationary Distribution Around an Optimum</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#connecting-to-frequentist-random-effects">3. Connecting to Frequentist Random Effects</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#implications-and-practical-considerations">4. Implications and Practical Considerations</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#summary-of-the-detailed-derivation">Summary of the Detailed Derivation</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#viewing-sgd-as-bootstrapping">Viewing SGD as Bootstrapping</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#formalizing-the-bootstrapping-analogy">Formalizing the Bootstrapping Analogy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implications-for-frequentist-inference">Implications for Frequentist Inference</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">In Summary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#polyakruppert-averaging">1. Polyak–Ruppert Averaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretation-in-the-context-of-deep-learning">2. Interpretation in the Context of Deep Learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bootstrapping-view">3. Bootstrapping View</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Summary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#local-convexity-in-nonconvex-objectives">1. Local Convexity in Nonconvex Objectives</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sgd-random-walk-and-local-convexity">2. SGD Random Walk and Local Convexity</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#caveats-and-practical-considerations">3. Caveats and Practical Considerations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">Conclusion</a></li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="deep-neural-networks-bridging-parametric-and-non-parametric-models">
<h1>Deep Neural Networks: Bridging Parametric and Non-Parametric Models<a class="headerlink" href="#deep-neural-networks-bridging-parametric-and-non-parametric-models" title="Link to this heading">#</a></h1>
<p><strong>1. Parametric Character:</strong></p>
<ul class="simple">
<li><p><strong>Definition:</strong> Deep neural networks (DNNs) are typically defined by a fixed architecture and a finite number of parameters (weights and biases). In this sense, they are <em>parametric models</em> because, once the architecture is set, the model is completely specified by these parameters.</p></li>
<li><p><strong>Overparameterization:</strong> Modern DNNs are often heavily overparameterized. That is, the number of parameters can greatly exceed the number of training examples, which in classical theory would seem to suggest a high risk of overfitting.</p></li>
</ul>
<p><strong>2. Non-Parametric-Like Behavior:</strong></p>
<ul class="simple">
<li><p><strong>Data-Dependent Representations:</strong> Instead of explicitly “storing” the training data as non-parametric models like k-nearest neighbors or Gaussian Processes do, deep nets learn to <em>encode an approximation of the data distribution</em> in their weights. In effect, the parameters capture information about the training examples in a compressed form.</p></li>
<li><p><strong>Infinite Capacity Behavior:</strong> Although the model is technically finite-dimensional, the structure of deep networks (with many layers and non-linear activation functions) enables them to approximate a vast set of functions. This is reminiscent of non-parametric methods, which can in principle approximate any function given enough data.</p></li>
</ul>
<p><strong>3. Role of Depth and Hierarchical Representations:</strong></p>
<ul class="simple">
<li><p><strong>Hierarchical Feature Extraction:</strong> Depth allows networks to build hierarchical representations where early layers capture simple features and later layers compose them into more complex, abstract representations. This hierarchical structure is a powerful inductive bias that helps to capture the underlying structure of the data.</p></li>
<li><p><strong>Effective Function Complexity:</strong> While deeper networks add parameters, these parameters are not free to move arbitrarily; they are constrained by the network architecture and the dynamics of gradient-based optimization. This means that even though the number of parameters is large, the <em>effective complexity</em> of the functions that the network can express is controlled.</p></li>
<li><p><strong>Implicit Regularization:</strong> Modern training practices—such as stochastic gradient descent (SGD), dropout, batch normalization, and weight decay—impose an <em>implicit regularization</em> on the learned functions. Empirically, this regularization prevents the network from overfitting despite its overparameterized nature. One can view this as the network converging to a solution that not only fits the training data but also has certain “smoothness” or “simplicity” properties in function space.</p></li>
</ul>
<p><strong>4. The Interplay Between Parametric and Non-Parametric Perspectives:</strong></p>
<ul class="simple">
<li><p><strong>Parameterization vs. Storage:</strong> Unlike traditional non-parametric methods that use the training data explicitly at prediction time (e.g., averaging the outputs of nearby points), deep nets “store” information about the training set in their weights during training. When making a prediction, the network computes a function value based on these weights rather than retrieving data points.</p></li>
<li><p><strong>Model Flexibility and Generalization:</strong> Deep nets are flexible enough to approximate very complex functions (a non-parametric trait) while maintaining a fixed, finite set of parameters (a parametric trait). This dual nature allows them to enjoy the adaptability of non-parametric models—able to fit intricate patterns—while also benefiting from the efficiency and regularization that arise from having a structured parameter space.</p></li>
<li><p><strong>Function Space Geometry:</strong> When viewed from the perspective of function spaces, each network weight configuration corresponds to a function in a high-dimensional space. The training process (e.g., via gradient descent) then becomes a navigation through this function space, where implicit biases (like favoring “simpler” or smoother functions) help the model generalize even with extensive parameterization.</p></li>
</ul>
<hr class="docutils" />
</section>
<section id="summary">
<h1>Summary<a class="headerlink" href="#summary" title="Link to this heading">#</a></h1>
<p>Deep neural networks are formally parametric because they have a fixed number of parameters. However, their overparameterization and the way these parameters are organized allow them to learn highly flexible, data-dependent representations. Rather than explicitly keeping the training data accessible at runtime (as in non-parametric methods), deep networks embed the necessary information into the weights, effectively acting as a compressed approximation of the data’s underlying structure. The depth and structure of these networks, along with both explicit and implicit forms of regularization, ensure that increased model capacity does not inevitably lead to overfitting. In this way, deep nets neatly bridge the gap between parametric and non-parametric modeling.</p>
</section>
<section id="why-do-we-place-priors-on-weights-instead-of-functions">
<h1>Why Do We Place Priors on Weights Instead of Functions?<a class="headerlink" href="#why-do-we-place-priors-on-weights-instead-of-functions" title="Link to this heading">#</a></h1>
<p>In Bayesian deep learning, we often place priors on the weights of a neural network rather than directly on the functions they represent. This choice is driven by several practical and theoretical considerations:</p>
<ol class="arabic simple">
<li><p><strong>Dimensionality and Complexity of Function Space:</strong><br />
The space of functions that a neural network can represent is vast and complex, especially as the number of parameters increases. Placing priors directly in this function space would require a deep understanding of the structure of this space, which is often not feasible.</p></li>
<li><p><strong>Overparameterization and Redundancy:</strong>
Neural networks are typically overparameterized, meaning that many different weight configurations can yield similar or even identical functions. This redundancy complicates the task of defining a meaningful prior in function space.</p></li>
<li><p><strong>Inference and Computation:</strong>
Bayesian inference methods (like variational inference or MCMC) are well-developed for finite-dimensional parameter spaces. Working directly in function space would complicate inference, as it would require dealing with infinite-dimensional distributions.</p></li>
</ol>
<p>The key challenge is that although it sounds appealing to work directly in function space, doing so would require characterizing a distribution over an incredibly complex and high-dimensional set of functions—something that is, in practice, much more difficult than working with the parameters that generate them. Here are several points to clarify this trade-off:</p>
<ol class="arabic simple">
<li><p><strong>Mapping from Weights to Functions Is Highly Nonlinear and Many-to-One:</strong><br />
Every weight vector ( \theta ) in a neural network induces a function ( f_\theta ). However, due to overparameterization and symmetry (e.g., swapping neurons in a hidden layer doesn’t change the function), many different weight configurations can correspond to the same—or very similar—functions. This many-to-one mapping makes it difficult to define a prior directly in function space without losing or overcounting structure.</p></li>
<li><p><strong>Specifying a Prior over Functions Is Conceptually Attractive but Practically Challenging:</strong><br />
In theory, one might define a prior ( p(f) ) over the space of functions, and treat the weights as latent variables that serve merely as a computational mechanism to represent ( f ). However, the space of functions ( \mathcal{F} ) is infinite-dimensional and highly complex. Defining a tractable, expressive, and well-calibrated prior on ( \mathcal{F} ) is a daunting mathematical and computational task. In contrast, it is much more straightforward to place a prior on the weights ( p(\theta) ), which, although high-dimensional, has a fixed finite dimension dictated by the architecture.</p></li>
<li><p><strong>Computational Tractability and Inference:</strong><br />
Bayesian inference techniques (whether variational approximations or Monte Carlo methods) are well-developed for finite-dimensional weight spaces. While the weight space is high-dimensional, modern variational inference methods and MCMC techniques have evolved to handle these scenarios by exploiting the structure of the weight space (e.g., using low-rank approximations or exploiting hierarchical models). Working directly in function space would complicate inference tremendously, as you’d have to directly represent and update an infinite-dimensional object.</p></li>
<li><p><strong>Implicit Function-Space Priors:</strong><br />
When we place a prior on weights, we induce an implicit prior on the functions the network can represent. In certain limits—for example, as neural networks become infinitely wide—the induced function-space prior converges to a Gaussian process. This indicates that our choice of weight-space priors does have a direct impact on the function space, even if it is not made explicit. Thus, while we are not setting ( p(f) ) directly, our weight priors are doing much of the work in shaping the behavior of ( f ).</p></li>
<li><p><strong>Recent Research Directions:</strong><br />
There is emerging work in “function-space variational inference” that attempts to work directly with distributions over functions. However, these methods remain challenging to implement at scale and are not as mature as the traditional weight-space approaches. They often require sophisticated approximations or significant computational overhead, which is why the community has largely stuck with weight-space priors despite their seeming inefficiencies.</p></li>
</ol>
<hr class="docutils" />
</section>
<section id="in-summary">
<h1>In Summary<a class="headerlink" href="#in-summary" title="Link to this heading">#</a></h1>
<p>Placing priors on the weights is a pragmatic choice that leverages our ability to work with finite-dimensional (albeit high-dimensional) parameter spaces. It allows us to use established inference methods and to indirectly control the induced function space. Explicitly formulating priors over functions might offer a more direct interpretation, but it introduces severe theoretical and computational challenges due to the complexity and infinite-dimensionality of function spaces. Thus, weights serve as convenient variational parameters that embody our beliefs about the functions we wish to learn.</p>
<p>Below is a more detailed derivation that builds on recent work (for example, see Mandt, Hoffman, &amp; Blei, 2017) and frames the SGD random walk as a basis for frequentist inference via random effects. The derivation proceeds in several steps.</p>
<hr class="docutils" />
</section>
<section id="sgd-as-a-stochastic-process">
<h1>1. SGD as a Stochastic Process<a class="headerlink" href="#sgd-as-a-stochastic-process" title="Link to this heading">#</a></h1>
<p>Assume the parameter update in SGD is given by</p>
<p>[
\theta_{t+1} = \theta_t - \eta, \nabla L(\theta_t) + \eta, \xi_t,
]</p>
<p>where</p>
<ul class="simple">
<li><p>(\theta_t) is the parameter vector at iteration (t),</p></li>
<li><p>(\eta) is the learning rate,</p></li>
<li><p>(\nabla L(\theta_t)) is the full-batch gradient of the loss (L(\theta)) (or an unbiased estimate of it), and</p></li>
<li><p>(\xi_t) is the noise arising from using minibatches; it typically has zero mean and some covariance (C(\theta_t)).</p></li>
</ul>
<p>For sufficiently small (\eta) and under appropriate regularity conditions, the discrete-time update can be approximated by a continuous-time stochastic differential equation (SDE). Writing time as (t) (interpreted in units of the learning rate) we have:</p>
<p>[
d\theta = -\nabla L(\theta), dt + \sqrt{2D(\theta)}, dW(t),
]</p>
<p>where (dW(t)) is the standard Wiener process (Brownian motion) and (D(\theta)) is an effective diffusion matrix. In many settings, one may approximate (D(\theta) \approx \eta, \Sigma(\theta)) where (\Sigma(\theta)) is the noise covariance due to minibatching. (In the limit of small learning rate and large batches, (\Sigma) might be approximated by the covariance of the stochastic gradient error.)</p>
<hr class="docutils" />
</section>
<section id="stationary-distribution-around-an-optimum">
<h1>2. Stationary Distribution Around an Optimum<a class="headerlink" href="#stationary-distribution-around-an-optimum" title="Link to this heading">#</a></h1>
<p>Suppose that (L(\theta)) is locally quadratic around its optimum (\theta^*):</p>
<p>[
L(\theta) \approx L(\theta^<em>) + \frac{1}{2}(\theta-\theta^</em>)^T H (\theta-\theta^*),
]</p>
<p>with the Hessian (H = \nabla^2 L(\theta^*)) (assumed positive definite). Under this quadratic approximation and assuming that (D(\theta) \approx D) is approximately constant in the local region, the SDE becomes analogous to the overdamped Langevin dynamics. In such a setting, the stationary distribution (p(\theta)) satisfies (in a formal sense):</p>
<p>[
p(\theta) \propto \exp!\Bigl(-\frac{L(\theta)}{T}\Bigr),
]</p>
<p>where (T) is an effective temperature that relates to the noise scale (in physical Langevin systems, (T) would be the actual temperature; in SGD, it relates to (\eta) and (\Sigma)). Under our quadratic loss assumption, the stationary distribution is Gaussian:</p>
<p>[
\theta \sim \mathcal{N}\Bigl(\theta^*,, \Sigma_\theta\Bigr),
]</p>
<p>with the covariance matrix given approximately by</p>
<p>[
\Sigma_\theta \approx T, H^{-1}.
]</p>
<p>More refined derivations (see Mandt et al.) show that when accounting for both the learning rate (\eta) and noise covariance (\Sigma), one obtains an effective relation of the form:</p>
<p>[
\Sigma_\theta \approx \eta, H^{-1}\Sigma, H^{-1}.
]</p>
<p>This covariance encapsulates the random fluctuations of SGD around the optimum.</p>
<hr class="docutils" />
</section>
<section id="connecting-to-frequentist-random-effects">
<h1>3. Connecting to Frequentist Random Effects<a class="headerlink" href="#connecting-to-frequentist-random-effects" title="Link to this heading">#</a></h1>
<p>In a traditional frequentist setting, inference on the parameter (\theta) is based on the sampling distribution of an estimator. Here, we obtain an empirical “sampling distribution” by viewing the SGD iterates as samples drawn from the stationary distribution ( \mathcal{N}(\theta^*, \Sigma_\theta) ).</p>
<ul class="simple">
<li><p><strong>Interpretation as Random Effects:</strong><br />
In mixed-effects models, one treats certain parameter variations as random effects. Analogously, the SGD iterates reflect a random effect—variations that arise from the noise in the optimization process. Instead of treating the optimum (\theta^*) as the sole estimator, one considers the observed variability of (\theta_t) to form confidence intervals or test statistics.</p></li>
<li><p><strong>Test Statistics as Random Quantities:</strong><br />
For instance, a test statistic (e.g., a likelihood ratio comparing a null hypothesis about (\theta)) can be calibrated by the empirical covariance (\Sigma_\theta). If we denote a linear approximation of a test statistic (T(\theta)), the fact that (\theta) fluctuates according to (\mathcal{N}(\theta^*, \Sigma_\theta)) allows us to derive the distribution of (T) under the null. This is a frequentist analog to constructing a posterior credible region—the “random effects” (the fluctuation of the iterates) provide the necessary uncertainty quantification.</p></li>
<li><p><strong>Stochastic Neyman–Pearson Approach:</strong><br />
In classical Neyman–Pearson theory, the optimal test is based on the likelihood ratio. Here, if we assume that near (\theta^*), the loss (L(\theta)) serves as a surrogate for the negative log-likelihood, the density (p(\theta)) derived above allows us to form a likelihood ratio test. However, rather than using a single point estimate from batch optimization, we can consider the distribution of SGD iterates to compute the test statistic. In effect, the observed random walk gives us an empirical approximation of the sampling distribution needed for testing.</p></li>
</ul>
<hr class="docutils" />
</section>
<section id="implications-and-practical-considerations">
<h1>4. Implications and Practical Considerations<a class="headerlink" href="#implications-and-practical-considerations" title="Link to this heading">#</a></h1>
<ul class="simple">
<li><p><strong>Parameter Uncertainty:</strong><br />
The covariance (\Sigma_\theta) derived above can be used to form confidence intervals around (\theta^*). In practice, one could run SGD long enough and record the trajectory; the empirical variance of these iterates can serve as a basis for uncertainty quantification.</p></li>
<li><p><strong>Regularization via Noise:</strong><br />
The effective temperature (T) (or equivalently, (\eta) and the minibatch size) regularizes the solution: larger noise encourages exploration of flatter minima (which often generalize better). The geometry of (H) (the curvature) and the scaling of (\Sigma) determine how tight the stationary distribution is.</p></li>
<li><p><strong>Algorithm Design:</strong><br />
Recognizing this structure may inspire techniques that explicitly account for SGD’s sampling distribution—for example, by using moving average estimates of the covariance or designing stopping criteria that balance bias and variance (akin to early stopping viewed through the lens of random effects).</p></li>
</ul>
<hr class="docutils" />
</section>
<section id="summary-of-the-detailed-derivation">
<h1>Summary of the Detailed Derivation<a class="headerlink" href="#summary-of-the-detailed-derivation" title="Link to this heading">#</a></h1>
<ol class="arabic simple">
<li><p><strong>SGD Update:</strong><br />
(\theta_{t+1} = \theta_t - \eta \nabla L(\theta_t) + \eta \xi_t.)</p></li>
<li><p><strong>SDE Approximation:</strong><br />
(d\theta = -\nabla L(\theta),dt + \sqrt{2D(\theta)},dW(t).)</p></li>
<li><p><strong>Quadratic Approximation Near (\theta^*):</strong><br />
(L(\theta) \approx L(\theta^<em>) + \frac{1}{2}(\theta-\theta^</em>)^T H (\theta-\theta^<em>),)<br />
leading to (\theta \sim \mathcal{N}(\theta^</em>, \Sigma_\theta)).</p></li>
<li><p><strong>Covariance Estimation:</strong><br />
(\Sigma_\theta \approx \eta, H^{-1}\Sigma, H^{-1}) (or, under a simplified model, (\Sigma_\theta \approx T, H^{-1})).</p></li>
<li><p><strong>Frequentist Inference:</strong><br />
The SGD iterates provide an empirical sampling distribution. One may then calibrate tests (e.g., Neyman–Pearson style) or construct confidence intervals using the estimated (\Sigma_\theta), effectively treating the fluctuations as random effects.</p></li>
</ol>
<hr class="docutils" />
<p>This derivation formalizes how we can leverage the stochastic behavior of deep network optimization—in particular, the random walk of SGD—as a basis for frequentist parameter inference. It connects the geometry of the loss landscape (via the Hessian (H)) with the noise structure (via (\Sigma)), and offers a pathway to develop inferential procedures grounded in the observed variability of the optimization process.</p>
</section>
<section id="references">
<h1>References<a class="headerlink" href="#references" title="Link to this heading">#</a></h1>
<ul class="simple">
<li><p>Mandt, S., Hoffman, M. D., &amp; Blei, D. M. (2017). Stochastic gradient descent as approximate Bayesian inference. <em>Journal of Machine Learning Research</em>, 18(1), 4873-4907.</p></li>
<li><p>Zhang, Y., &amp; Sabuncu, M. R. (2018). Generalized cross entropy loss for training deep neural networks with a softmax output layer. <em>arXiv preprint arXiv:1805.07836</em>.</p></li>
<li><p>Wainwright, M. J. (2019). High-dimensional statistics: A non-asymptotic viewpoint. <em>Cambridge University Press</em>.</p></li>
</ul>
<p>Below is an explanation that frames SGD as a form of bootstrapping, highlighting how the repeated resampling of mini‐batches offers an alternative way to quantify uncertainty in parameter estimates—similar in spirit to bootstrap methods in classical statistics.</p>
<hr class="docutils" />
<section id="viewing-sgd-as-bootstrapping">
<h2>Viewing SGD as Bootstrapping<a class="headerlink" href="#viewing-sgd-as-bootstrapping" title="Link to this heading">#</a></h2>
<p>When we perform stochastic gradient descent (SGD), we do not compute a gradient on the entire dataset at each update; instead, we sample a mini-batch of data and use it to compute an approximate gradient. This process has two important consequences:</p>
<ol class="arabic simple">
<li><p><strong>Implicit Resampling of the Data:</strong><br />
Because each mini-batch is effectively a random re-sample from the full dataset, SGD introduces variability into the gradient estimates. In traditional bootstrap methods, one repeatedly resamples (with replacement) from the data to generate an empirical distribution of an estimator. Similarly, in SGD, the use of different mini-batches provides different, noisy estimates of the “true” gradient and objective value. Over many iterations, these fluctuating estimates can be thought of as a kind of bootstrap sample of the underlying parameter estimates.</p></li>
<li><p><strong>Bootstrapped Parameter Trajectories:</strong><br />
In a batch optimization scenario, one generally focuses on a single point estimate—the global optimum. In contrast, the trajectory of SGD does not settle exactly at one point due to its inherent noise. Instead, it “wanders” around the optimum, effectively sampling from a distribution of parameter values. This wandering is analogous to how bootstrap replicates provide multiple estimates of a parameter: each SGD step (or, more accurately, the aggregated parameter values over several steps) can be viewed as one bootstrap draw. Thus, the variance observed in SGD iterates can be used to infer the uncertainty of our parameter estimates.</p></li>
</ol>
</section>
<hr class="docutils" />
<section id="formalizing-the-bootstrapping-analogy">
<h2>Formalizing the Bootstrapping Analogy<a class="headerlink" href="#formalizing-the-bootstrapping-analogy" title="Link to this heading">#</a></h2>
<p>Consider the standard SGD update:
[
\theta_{t+1} = \theta_t - \eta, \nabla L(\theta_t; \mathcal{B}_t),
]
where (\mathcal{B}_t) is the mini-batch at iteration (t). Each mini-batch (\mathcal{B}_t) is a random sample from the full dataset, so that the gradient (\nabla L(\theta_t; \mathcal{B}_t)) is a random variable whose expectation approximates the true gradient (\nabla L(\theta_t)).</p>
<p>In classical bootstrap methods, one generates multiple datasets by resampling the observed data and then computes parameter estimates on each replicate. The variability among these replicates gives a measure of the uncertainty of the parameter estimates. In the SGD scenario:</p>
<ul class="simple">
<li><p><strong>Mini-batch Noise as Resampling:</strong><br />
Each mini-batch provides a “resampled” view of the full data, and the corresponding SGD update is analogous to a bootstrap sample of the gradient.</p></li>
<li><p><strong>Accumulated Variability:</strong><br />
As training proceeds, the collection of iterates ({\theta_t}) reflects the variability induced by the different mini-batches. Rather than converging to a single value (as in batch optimization), the distribution of ({\theta_t}) reflects a sampling distribution that contains information about uncertainty—similar to a bootstrap distribution.</p></li>
</ul>
<p>One can then imagine using this empirical distribution—for instance, by averaging over a time window after a burn-in period—as an estimate of the true parameter value and its variability. This perspective suggests a framework for constructing confidence intervals or hypothesis tests based on the SGD trajectory, where the “randomness” induced by mini-batch sampling plays the role of the resampling mechanism in bootstrap inference.</p>
</section>
<hr class="docutils" />
<section id="implications-for-frequentist-inference">
<h2>Implications for Frequentist Inference<a class="headerlink" href="#implications-for-frequentist-inference" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><strong>Uncertainty Quantification:</strong><br />
Just as classical bootstrap methods allow us to compute standard errors and confidence intervals by considering the variability across bootstrap samples, one could design methods that use the spread of SGD iterates to assess the uncertainty of parameter estimates.</p></li>
<li><p><strong>Stochastic Optimization as a Natural Resampler:</strong><br />
This perspective provides a conceptual basis for why repeated passes over mini-batches, rather than a single batch optimization, might yield a more realistic picture of the uncertainty, as it inherently captures the random fluctuations arising from subsampling the data.</p></li>
<li><p><strong>Bridging to Random Effects:</strong><br />
This bootstrapping viewpoint complements the random effects interpretation—both view the observed variation in parameter estimates (through SGD) as reflective of underlying uncertainty, either as a latent random effect or as the result of repeated resampling.</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="id1">
<h2>In Summary<a class="headerlink" href="#id1" title="Link to this heading">#</a></h2>
<p>Viewing SGD as a form of bootstrapping provides an alternative frequentist framework for parameter inference. In this view, each mini-batch acts like a bootstrap sample, and the resulting trajectory of SGD is analogous to a bootstrap distribution of parameter estimates. This variability can then be harnessed—similar to classical bootstrap methods—to construct confidence intervals or tests that account for the inherent uncertainty in deep learning models. Although the correlation between sequential mini-batches and the dynamic behavior of SGD complicates a direct application of bootstrap theory, this analogy offers a promising route for developing robust, uncertainty-aware inference methods in deep neural networks.</p>
<p>Under fairly general conditions—especially in convex settings—it is possible to characterize the asymptotic distribution of the average parameter estimate obtained by SGD. This result is most notably captured by the <strong>Polyak–Ruppert averaging</strong> framework. Here’s an outline of the key points and derivations:</p>
</section>
<hr class="docutils" />
<section id="polyakruppert-averaging">
<h2>1. Polyak–Ruppert Averaging<a class="headerlink" href="#polyakruppert-averaging" title="Link to this heading">#</a></h2>
<p>Suppose we are minimizing a smooth, convex loss function ( L(\theta) ) and the SGD iterates are given by</p>
<p>[
\theta_{t+1} = \theta_t - \eta_t , \nabla L(\theta_t) + \eta_t , \xi_t,
]</p>
<p>where (\eta_t) is the learning rate and (\xi_t) is the stochastic noise (assumed to be zero mean and with some covariance structure). Under suitable conditions (e.g., a decreasing step size or constant step size with iterate averaging, smoothness, and strong convexity of (L)), one can show that the <strong>averaged iterate</strong></p>
<p>[
\bar{\theta}<em>T = \frac{1}{T} \sum</em>{t=1}^{T} \theta_t
]</p>
<p>converges to the true optimum (\theta^*) and—more importantly—satisfies an asymptotic normality result:</p>
<p>[
\sqrt{T}, (\bar{\theta}_T - \theta^*) \overset{d}{\to} \mathcal{N}(0, \Sigma),
]</p>
<p>where the asymptotic covariance (\Sigma) is typically given by</p>
<p>[
\Sigma = H^{-1} S H^{-1}.
]</p>
<p>Here,</p>
<ul class="simple">
<li><p>(H = \nabla^2 L(\theta^*)) is the Hessian (or Fisher information, when (L) is the negative log-likelihood) at the optimum, and</p></li>
<li><p>(S) is the covariance matrix of the stochastic gradient noise (often defined via (S = \mathbb{E}[\xi_t \xi_t^T])).</p></li>
</ul>
<p>This result—established in works by Polyak and Ruppert in the 1980s and 1990s—shows that even though individual SGD iterates may not converge, their average does, and this average behaves like a classical maximum likelihood estimator under standard regularity conditions.</p>
</section>
<hr class="docutils" />
<section id="interpretation-in-the-context-of-deep-learning">
<h2>2. Interpretation in the Context of Deep Learning<a class="headerlink" href="#interpretation-in-the-context-of-deep-learning" title="Link to this heading">#</a></h2>
<p>For deep neural networks, while the loss surface is non-convex and many of the classical assumptions do not strictly hold, the intuition carries over in a heuristic sense:</p>
<ul class="simple">
<li><p><strong>Averaging mitigates variance:</strong> Deep networks are often overparameterized and trained with noisy SGD. Averaging the iterates (or using other techniques that mimic averaging, such as running average or “temporal ensembling”) can reduce the variance of the estimate.</p></li>
<li><p><strong>Implicit regularization:</strong> The noise in SGD not only prevents full convergence to a single point but also acts as an implicit regularizer. When averaged, the trajectory can be seen as sampling from a distribution that is “centered” at a broad, flat minimum. This flatness is often linked to better generalization.</p></li>
<li><p><strong>Approximate Gaussianity:</strong> Although deep learning models are highly non-convex, recent research (for example, Mandt, Hoffman, and Blei, 2017) has suggested that under appropriate conditions, SGD can be approximated by a Langevin dynamics process, which in its stationary regime yields a Gaussian-like distribution around the optimum.</p></li>
</ul>
<p>Thus, from a practical standpoint, one can sometimes use the empirical variability observed in SGD iterates to form uncertainty estimates or even design hypothesis tests. These methods, however, are an active area of research in deep learning due to the additional complications arising from non-convexity, heavy overparameterization, and the complexity of the loss landscape.</p>
</section>
<hr class="docutils" />
<section id="bootstrapping-view">
<h2>3. Bootstrapping View<a class="headerlink" href="#bootstrapping-view" title="Link to this heading">#</a></h2>
<p>An alternative perspective views the variability in the SGD iterates as akin to a bootstrap distribution. Since each mini-batch produces a slightly different gradient—and hence a slightly different update—the averaged SGD iterates can be interpreted as “resampled” estimates of the parameter. Under this view, the distribution of the averaged parameter estimate approximates the sampling distribution one would obtain by bootstrapping the data. This connection further reinforces why, under suitable conditions, (\bar{\theta}_T) would be approximately normally distributed.</p>
</section>
<hr class="docutils" />
<section id="id2">
<h2>Summary<a class="headerlink" href="#id2" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><strong>Theorem (Polyak–Ruppert averaging):</strong> Under suitable conditions, the average SGD iterate (\bar{\theta}_T) satisfies
[
\sqrt{T}, (\bar{\theta}_T - \theta^*) \overset{d}{\to} \mathcal{N}(0, H^{-1} S H^{-1}).
]</p></li>
<li><p>In deep learning, even when classical assumptions are loosened, the averaged iterates often empirically exhibit a degree of normality. This observation can be used for uncertainty quantification and further statistical inference.</p></li>
<li><p>Viewing SGD as a bootstrap mechanism emphasizes that the randomness in mini-batch selection provides a natural way to “resample” and hence quantify the variability in the parameter estimates.</p></li>
</ul>
<p>Yes, it is often considered reasonable to assume local convexity in the neighborhood of a minimum—even for generally nonconvex objectives—if the SGD iterates have settled into a “well-behaved” region of the parameter space. Here’s a detailed explanation:</p>
</section>
<hr class="docutils" />
<section id="local-convexity-in-nonconvex-objectives">
<h2>1. Local Convexity in Nonconvex Objectives<a class="headerlink" href="#local-convexity-in-nonconvex-objectives" title="Link to this heading">#</a></h2>
<p>Even though many deep learning loss surfaces are nonconvex overall, empirical observations and theoretical work have suggested that near a local minimum (especially a wide and flat one), the loss function can often be approximated well by a quadratic function. In other words, within a small enough neighborhood, the Hessian (the matrix of second derivatives) is nearly positive definite. This implies that the loss is locally convex. Such an assumption is common in:</p>
<ul class="simple">
<li><p><strong>Quadratic Approximations:</strong><br />
When performing second-order analysis or Laplace approximations, practitioners assume that near the optimum ( \theta^* ), the loss ( L(\theta) ) can be approximated as<br />
[
L(\theta) \approx L(\theta^<em>) + \frac{1}{2}(\theta-\theta^</em>)^T H (\theta-\theta^<em>),
]
where ( H = \nabla^2 L(\theta^</em>) ) is the Hessian, assumed to have all nonnegative eigenvalues in that local region.</p></li>
<li><p><strong>Empirical Studies of Deep Networks:</strong><br />
Research has shown that in deep learning, many minima that SGD converges to exhibit “flat” geometry. In these regions, the loss landscape is relatively smooth and locally well approximated by a convex (or nearly convex) quadratic function. This observation is one of the reasons why even highly overparameterized deep networks can generalize well despite nonconvexity at a global level.</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="sgd-random-walk-and-local-convexity">
<h2>2. SGD Random Walk and Local Convexity<a class="headerlink" href="#sgd-random-walk-and-local-convexity" title="Link to this heading">#</a></h2>
<p>When you analyze the trajectory of SGD as a random walk near a local optimum, you are effectively sampling from a region where the loss is approximately quadratic. The assumptions underlying classical results—like Polyak–Ruppert averaging—rely on this local convexity to derive that the averaged iterate converges in distribution to a normal distribution. In this context:</p>
<ul class="simple">
<li><p><strong>Gradient Noise and Hessian:</strong><br />
The fluctuations caused by mini-batch noise can be modeled as driving dynamics in a locally convex “bowl.” This lets you use results from the theory of stochastic differential equations (SDEs) for convex functions.</p></li>
<li><p><strong>Small Neighborhood Assumption:</strong><br />
If the SGD random walk is contained in a small neighborhood around ( \theta^* ), the local convexity assumption is quite reasonable. The noise helps the iterates explore this local region, and the average of these iterates is then influenced by the local curvature (captured by ( H )) and noise covariance.</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="caveats-and-practical-considerations">
<h2>3. Caveats and Practical Considerations<a class="headerlink" href="#caveats-and-practical-considerations" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><strong>Not Universally True:</strong><br />
While many local minima satisfy these conditions, it’s important to recognize that there can still be directions with nearly zero or even negative curvature. However, by focusing on wide and flat minima (as many studies suggest SGD implicitly does), the dominant behavior is often nearly convex.</p></li>
<li><p><strong>Dependence on Model and Data:</strong><br />
The validity of the local convexity approximation may depend on the particular neural network architecture, regularization strategy, and dataset. In practice, many analyses rely on empirical evidence that the local regions are “nice enough” for the approximations to hold.</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Link to this heading">#</a></h2>
<p>Thus, even though deep learning objectives are globally nonconvex, it is both common and often reasonable to assume local convexity when analyzing the behavior of SGD around a converged region. This assumption is useful for developing theoretical insights—such as the asymptotic normality of the averaged SGD iterate—and for devising frequentist inference procedures that leverage the observed randomness of SGD.
This perspective allows us to bridge the gap between the nonconvex nature of deep learning and the tractable analysis provided by local convexity, enabling effective statistical inference in practice.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chapter_spaces"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Deep Neural Networks: Bridging Parametric and Non-Parametric Models</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#why-do-we-place-priors-on-weights-instead-of-functions">Why Do We Place Priors on Weights Instead of Functions?</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#in-summary">In Summary</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#sgd-as-a-stochastic-process">1. SGD as a Stochastic Process</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#stationary-distribution-around-an-optimum">2. Stationary Distribution Around an Optimum</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#connecting-to-frequentist-random-effects">3. Connecting to Frequentist Random Effects</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#implications-and-practical-considerations">4. Implications and Practical Considerations</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#summary-of-the-detailed-derivation">Summary of the Detailed Derivation</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#viewing-sgd-as-bootstrapping">Viewing SGD as Bootstrapping</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#formalizing-the-bootstrapping-analogy">Formalizing the Bootstrapping Analogy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implications-for-frequentist-inference">Implications for Frequentist Inference</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">In Summary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#polyakruppert-averaging">1. Polyak–Ruppert Averaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretation-in-the-context-of-deep-learning">2. Interpretation in the Context of Deep Learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bootstrapping-view">3. Bootstrapping View</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Summary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#local-convexity-in-nonconvex-objectives">1. Local Convexity in Nonconvex Objectives</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sgd-random-walk-and-local-convexity">2. SGD Random Walk and Local Convexity</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#caveats-and-practical-considerations">3. Caveats and Practical Considerations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">Conclusion</a></li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Christoph Lippert
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <script src="https://giscus.app/client.js"
        data-repo="HealthML/Math4ML"
        data-repo-id="R_kgDON-O79w"
        data-category="Comments"
        data-category-id="DIC_kwDON-O7984Co2qc"
        data-mapping="pathname"
        data-strict="1"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-input-position="top"
        data-theme="preferred_color_scheme"
        data-lang="en"
        data-loading="lazy"
        crossorigin="anonymous"
        async>
</script>

</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>