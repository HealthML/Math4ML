
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>The Jacobian &#8212; Mathematics for Machine Learning</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapter_calculus/jacobian';</script>
    <link rel="canonical" href="https://healthml.github.io/Math4ML/chapter_calculus/jacobian.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="The chain rule" href="chain_rule.html" />
    <link rel="prev" title="Matrix calculus" href="matrix_calculus.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/hpi-logo-colored.svg" class="logo__image only-light" alt="Mathematics for Machine Learning - Home"/>
    <script>document.write(`<img src="../_static/hpi-logo-colored.svg" class="logo__image only-dark" alt="Mathematics for Machine Learning - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    Preface
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Mathematics for Machine Learning</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_ml_basics/intro.html">Machine Learning Problems</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_ml_basics/classification.html">Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_ml_basics/regression.html">Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_ml_basics/clustering.html">Clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_ml_basics/representation_learning.html">Representation Learning</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_spaces/overview_spaces.html">Vector and Function Spaces</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_spaces/vector_spaces.html">Vector Spaces</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_spaces/polynomial_vector_space.html">Polynomial Vector Space</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_spaces/basis_functions_vector_space.html">Basis Functions Vector Space</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_spaces/subspaces.html">Subspaces</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_spaces/metric_spaces.html">Metric Spaces</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_spaces/normed_spaces.html">Normed Spaces</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_spaces/inner_product_spaces.html">Inner Product Spaces</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_spaces/transposition.html">Transposition</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="overview_calculus.html">Calculus and Optimization</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="extrema.html">Extrema</a></li>
<li class="toctree-l2"><a class="reference internal" href="gradients.html">Gradients</a></li>
<li class="toctree-l2"><a class="reference internal" href="gradient_descent_ridge.html">Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="matrix_calculus.html">Matrix Calculus</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Jacobian</a></li>
<li class="toctree-l2"><a class="reference internal" href="chain_rule.html">Chain Rule</a></li>
<li class="toctree-l2"><a class="reference internal" href="mean_value_theorem.html">Mean Value Theorem</a></li>
<li class="toctree-l2"><a class="reference internal" href="minima_first_order_condition.html">First Order Condition</a></li>
<li class="toctree-l2"><a class="reference internal" href="analytical_solution_ridge.html">Quadratic Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="line_search.html">Line Search</a></li>
<li class="toctree-l2"><a class="reference internal" href="hessian.html">Hessian</a></li>
<li class="toctree-l2"><a class="reference internal" href="taylors_theorem.html">Taylor’s Theorem</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_decompositions/overview_decompositions.html">Matrix Analysis</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_decompositions/matrix_rank.html">Rank of a Matrix</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_decompositions/determinant.html">Determinant</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_decompositions/row_equivalence.html">Gaussian Elimination and the PLU Decomposition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_decompositions/square_matrices.html">Fundamental Equivalences for Square matrices</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_decompositions/trace.html">Trace</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_decompositions/eigenvectors.html">Eigenvalues and Eigenvectors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_decompositions/orthogonal_matrices.html">Orthogonal matrices</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_decompositions/symmetric_matrices.html">Symmetric matrices</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_decompositions/Rayleigh_quotients.html">Rayleigh Quotients</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_decompositions/matrix_norms.html">Matrix Norms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_decompositions/psd_matrices.html">Positive (semi-)definite matrices</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_decompositions/pca.html">Principal Components Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_decompositions/svd.html">Singular value decomposition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_decompositions/pseudoinverse.html">Moore-Penrose Pseudoinverse</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_decompositions/orthogonal_projections.html">Orthogonal projections</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_decompositions/big_picture.html">Fundamental Subspaces</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_convexity/overview_convexity.html">Convexity</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convexity/convex_sets.html">Convex sets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convexity/convex_functions.html">Basics of convex functions</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_second_order/overview_second_order.html">Second-Order Optimization</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_second_order/minima_second_order_condition.html">Second Order Condition for Minima</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_second_order/newtons_method.html">Newton’s Method</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_probability/overview_probability.html">Probability</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_probability/probability_basics.html">Probability Basics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_probability/random_variables.html">Random variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_probability/functions_of_random_variables.html">Functions of Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_probability/expectation.html">Expected Value</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_probability/variance.html">Variance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_probability/covariance.html">Covariance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_probability/random_vectors.html">Random vectors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_probability/functions_random_vectors.html">Functions of Random Vectors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_probability/joint_distributions.html">Joint distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_probability/gaussian.html">The Gaussian distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_probability/estimation.html">Estimation of Parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_probability/exponential_family.html">The Exponential Family and Conjugate Priors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_probability/bayesian_inference_Gaussian.html">Bayesian Inference for the Gaussian</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendix</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../appendix/proofs.html">Detailed Proofs</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../appendix/Cauchy%E2%80%93Schwarz_inequality.html">Cauchy-Schwarz Inequality</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix/Bolzano-Weierstrass_theorem.html">Bolzano-Weierstrass Theorem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix/extreme_value_theorem.html">Extreme Value Theorem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix/Rolles_theorem.html">Rolle's Theorem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix/mean_value_theorem_proof.html">Mean Value Theorem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix/scalar-scalar_chain_rule.html">Chain Rule for Scalar-Scalar Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix/squeeze_theorem.html">Squeeze Theorem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix/first_fundamental_theorem_calculus.html">First Fundamental Theorem of Calculus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix/second_fundamental_theorem_calculus.html">Second Fundamental Theorem of Calculus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix/Clairauts_theorem.html">Clairaut's Theorem</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../appendix/differentiation_rules.html">Differentiation Rules</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../appendix/Exercise%20Sheet%20Solutions.html">Exercise Sheet Solutions</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../appendix/Exercise%20Sheet%201%20Solutions.html">Exercise Sheet 1 Solutions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix/Exercise%20Sheet%202%20Solutions.html">Exercise Sheet 2 Solutions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix/Exercise%20Sheet%203%20Solutions.html">Exercise Sheet 3 Solutions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix/Exercise%20Sheet%204%20Solutions.html">Exercise Sheet 4 Solutions</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/HealthML/Math4ML" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/HealthML/Math4ML/edit/main/book/chapter_calculus/jacobian.md" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/HealthML/Math4ML/issues/new?title=Issue%20on%20page%20%2Fchapter_calculus/jacobian.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/chapter_calculus/jacobian.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>The Jacobian</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#basis-functions-and-their-jacobians">Basis Functions and their Jacobians</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#jacobian-of-tanh-basis-functions">Jacobian of tanh basis functions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#partial-derivative-for-the-weights-a-kd">Partial derivative for the weights <span class="math notranslate nohighlight">\(a_{kd}\)</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#chain-rule-decomposition">1. Chain-rule decomposition</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#compute-each-factor">2. Compute each factor</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#put-it-together">3. Put it together</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#matrix-form-view">Matrix-form view</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#partial-derivative-for-the-weights-b-k">Partial derivative for the weights <span class="math notranslate nohighlight">\(b_k\)</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizing-the-jacobian-of-tanh-basis-functions"><strong>Visualizing the Jacobian of Tanh Basis Functions</strong></a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="the-jacobian">
<h1>The Jacobian<a class="headerlink" href="#the-jacobian" title="Link to this heading">#</a></h1>
<p>In machine learning, most of the time we’re optimizing a scalar “loss,” but internally the models we train are often vector-valued mappings.</p>
<p>Wherever you see a function with multiple outputs, like</p>
<div class="math notranslate nohighlight">
\[
  f: \mathbb{R}^n \;\longrightarrow\; \mathbb{R}^m
\]</div>
<p>you’ll want its <strong>Jacobian</strong>.</p>
<p>The Jacobian is the matrix of first-order partial derivatives of each output of <span class="math notranslate nohighlight">\(f\)</span> with respect to each of the input dimensions. It generalizes the gradient of a scalar-valued function to vector-valued functions.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mathbf{J}_f = \begin{bmatrix}
    \frac{\partial f_1}{\partial x_1} &amp; \dots &amp; \frac{\partial f_1}{\partial x_n} \\
    \vdots &amp; \ddots &amp; \vdots \\
    \frac{\partial f_m}{\partial x_1} &amp; \dots &amp; \frac{\partial f_m}{\partial x_n}\end{bmatrix}
\hspace{0.5cm}\text{i.e.}\hspace{0.5cm}
[\mathbf{J}_f]_{ij} = \frac{\partial f_i}{\partial x_j}\end{split}\]</div>
<p>Note the special case <span class="math notranslate nohighlight">\(m = 1\)</span>, where <span class="math notranslate nohighlight">\(\nabla f = \mathbf{J}_f^{\!\top\!}\)</span>.</p>
<section id="basis-functions-and-their-jacobians">
<h2>Basis Functions and their Jacobians<a class="headerlink" href="#basis-functions-and-their-jacobians" title="Link to this heading">#</a></h2>
<p>We have seen vector-valued functions in the context of <strong>basis functions</strong> such as the tanh basis functions that we used in the prediction of temperature as a function of the day in the year.</p>
<p>In the context of basis functions, we have a function <span class="math notranslate nohighlight">\(\boldsymbol{\phi}\)</span> that transforms the input data <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> into a new feature space. The basis functions are typically parameterized by weights and biases, and they can be thought of as nonlinear transformations of the input data.
The goal of using basis functions is to create a new feature space that can better capture the underlying structure of the data, allowing for more flexible modeling.</p>
<p>In order to optimize over the basis functions, we need to compute their Jacobian. What are the inputs and what are the outputs of the basis functions?</p>
<p>If we have <span class="math notranslate nohighlight">\(K\)</span> basis functions, these transform a <span class="math notranslate nohighlight">\(D\)</span>-dimensional feature vector <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> into a <span class="math notranslate nohighlight">\(K\)</span>-dimensional vector <span class="math notranslate nohighlight">\(\boldsymbol{\phi}_\boldsymbol{\theta}(\mathbf{x})\)</span>.</p>
<div class="math notranslate nohighlight">
\[
\boldsymbol{\phi}_\boldsymbol{\theta}(\mathbf{x}): \mathbb{R}^D \rightarrow \mathbb{R}^K
\]</div>
<p>Here, <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> is the vector of parameters of <span class="math notranslate nohighlight">\(\boldsymbol{\phi}\)</span>.</p>
<p>In machine learning our goal will be to optimize over these features based on a loss function computed over a fixed training data set of size <span class="math notranslate nohighlight">\(N\)</span> that is transformed using <span class="math notranslate nohighlight">\(\boldsymbol{\phi}\)</span>. Thus, we need to understand how the transformed data features of the training data set change as we modify the parameters <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span>.</p>
<p>In this view, we have to treat the parameters <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> as the input and the transformed data set as the output of <span class="math notranslate nohighlight">\(\boldsymbol{\phi}\)</span>.</p>
<div class="math notranslate nohighlight">
\[
\boldsymbol{\phi}_{\mathbf{X}}(\boldsymbol{\theta}): \mathbb{R}^{P}\rightarrow\mathbb{R}
^{NK},\]</div>
<p>where <span class="math notranslate nohighlight">\(P\)</span> is the total number of parameters of all the basis functions.</p>
<p>Thus, the Jacobian will be a matrix of size <span class="math notranslate nohighlight">\(P\)</span> times <span class="math notranslate nohighlight">\((NK)\)</span>.</p>
<p>To better keep track of the dimensions, we can think of the Jacobian as a <span class="math notranslate nohighlight">\(P\)</span>-by-<span class="math notranslate nohighlight">\(K\)</span> matrix for each data point <span class="math notranslate nohighlight">\(n\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbf{J}_{\boldsymbol{\phi}}(\mathbf{x}_n) = \begin{bmatrix}
    \frac{\partial \phi_{n1}}{\partial \theta_1} &amp; \dots &amp; \frac{\partial \phi_{n1}}{\partial \theta_P} \\
    \vdots &amp; \ddots &amp; \vdots \\
    \frac{\partial \phi_{nK}}{\partial \theta_1} &amp; \dots &amp; \frac{\partial \phi_{nK}}{\partial \theta_P}\end{bmatrix}
\hspace{0.5cm}\text{i.e.}\hspace{0.5cm}
[\mathbf{J}_{\boldsymbol{\phi}}]_{n, k; p} = \frac{\partial \phi_{nk}}{\partial \theta_p}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(n\)</span> is the index of the data point, <span class="math notranslate nohighlight">\(k\)</span> is the index of the basis function, and <span class="math notranslate nohighlight">\(p\)</span> is the index of the parameter.</p>
</section>
<section id="jacobian-of-tanh-basis-functions">
<h2>Jacobian of tanh basis functions<a class="headerlink" href="#jacobian-of-tanh-basis-functions" title="Link to this heading">#</a></h2>
<p>Let’s apply this to an example, where we transform the data using <span class="math notranslate nohighlight">\(K\)</span> tanh basis functions.</p>
<p>Let <span class="math notranslate nohighlight">\(\phi_{nk}\)</span> be the <span class="math notranslate nohighlight">\(k\)</span>-th basis-function activation on the <span class="math notranslate nohighlight">\(n\)</span>-th sample.</p>
<div class="math notranslate nohighlight">
\[
\phi_{nk}
=\tanh\!\bigl(z_{nk}\bigr)
\quad\text{with}\quad
z_{nk} \;=\;\sum_{d=1}^D a_{dk}\,x_{nd}\;+\;b_k
\]</div>
<p>So, the parameters of the basis functions are the weights <span class="math notranslate nohighlight">\(a_{dk}\)</span> and the biases <span class="math notranslate nohighlight">\(b_k\)</span>.
The weights <span class="math notranslate nohighlight">\(a_{dk}\)</span> are the slopes of the <span class="math notranslate nohighlight">\(k\)</span>-th basis function with respect to the <span class="math notranslate nohighlight">\(d\)</span>-th input feature, and the biases <span class="math notranslate nohighlight">\(b_k\)</span> are the offsets of the <span class="math notranslate nohighlight">\(k\)</span>-th basis function.</p>
<section id="partial-derivative-for-the-weights-a-kd">
<h3>Partial derivative for the weights <span class="math notranslate nohighlight">\(a_{kd}\)</span><a class="headerlink" href="#partial-derivative-for-the-weights-a-kd" title="Link to this heading">#</a></h3>
<div class="math notranslate nohighlight">
\[
\frac{\partial\,\phi_{nk}}{\partial\,a_{d\ell}}
\quad,\quad
d\in\{1,\dots,D\},\;k,\ell\in\{1,\dots,K\}.
\]</div>
</section>
<hr class="docutils" />
<section id="chain-rule-decomposition">
<h3>1. Chain-rule decomposition<a class="headerlink" href="#chain-rule-decomposition" title="Link to this heading">#</a></h3>
<p>By the chain rule,</p>
<div class="math notranslate nohighlight">
\[
\frac{\partial\,\phi_{nk}}{\partial\,a_{d\ell}}
=\underbrace{\frac{d}{dz}\tanh(z)\Big|_{z=z_{nk}}}_{\tanh'(z_{nk})}
\;\times\;
\frac{\partial\,z_{nk}}{\partial\,a_{d\ell}}.
\]</div>
</section>
<hr class="docutils" />
<section id="compute-each-factor">
<h3>2. Compute each factor<a class="headerlink" href="#compute-each-factor" title="Link to this heading">#</a></h3>
<ol class="arabic">
<li><p><strong>Derivative of tanh</strong></p>
<div class="math notranslate nohighlight">
\[
   \frac{d}{dz}\tanh(z)
   =1 - \tanh^2(z)
   \;\;\;\Longrightarrow\;\;\;
   \tanh'(z_{nk}) = 1 - \tanh^2\bigl(z_{nk}\bigr)
   = 1 - \phi_{nk}^2.
   \]</div>
</li>
<li><p><strong>Derivative of the affine argument</strong></p>
<div class="math notranslate nohighlight">
\[\begin{split}
   z_{nk}
   = \sum_{d=1}^D a_{dk}\,x_{nd} + b_k
   \quad\Longrightarrow\quad
   \frac{\partial z_{nk}}{\partial a_{d\ell}}
   = 
   \begin{cases}
     x_{nd}, &amp; \ell = k,\\
     0,      &amp; \ell \neq k.
   \end{cases}
   \end{split}\]</div>
</li>
</ol>
</section>
<hr class="docutils" />
<section id="put-it-together">
<h3>3. Put it together<a class="headerlink" href="#put-it-together" title="Link to this heading">#</a></h3>
<p>Hence</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\boxed{
\frac{\partial\,\phi_{nk}}{\partial\,a_{d\ell}}
=
\begin{cases}
\bigl(1 - \phi_{nk}^2\bigr)\;x_{nd}, 
&amp; \ell=k,\\
0, 
&amp; \ell\neq k.
\end{cases}
}
\end{split}\]</div>
<p>Equivalently, in one expression using the Kronecker delta <span class="math notranslate nohighlight">\(\delta_{\ell k}\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\frac{\partial\,\phi_{nk}}{\partial\,a_{d\ell}}
= \delta_{\ell k}\;\bigl(1 - \phi_{nk}^2\bigr)\;x_{nd}.
\]</div>
<p>We can see that the Jacobian has plenty of zeros, as the parameter of the <span class="math notranslate nohighlight">\(k\)</span>-th basis function only have an effect on the output of the <span class="math notranslate nohighlight">\(k\)</span>-th basis function and thus the partial derivatives for all the other basis functions are zero. This is a consequence of the fact that the tanh basis functions are independent of each other.</p>
</section>
<section id="matrix-form-view">
<h3>Matrix-form view<a class="headerlink" href="#matrix-form-view" title="Link to this heading">#</a></h3>
<p>If we collect all <span class="math notranslate nohighlight">\(\phi_{nk}\)</span> into an <span class="math notranslate nohighlight">\(N\times K\)</span> matrix <span class="math notranslate nohighlight">\(\boldsymbol{\Phi}\)</span>, and all weights <span class="math notranslate nohighlight">\(a_{dk}\)</span> into a <span class="math notranslate nohighlight">\(D\times K\)</span> matrix <span class="math notranslate nohighlight">\(\mathbf{A}\)</span>, then the Jacobian <span class="math notranslate nohighlight">\(\tfrac{\partial\,\boldsymbol{\Phi}}{\partial\,\mathbf{A}}\)</span> is a 4-tensor with entries</p>
<div class="math notranslate nohighlight">
\[
\bigl[J_{\boldsymbol{\Phi},\mathbf{A}}\bigr]_{\,n,k\,;\,d,\ell}
=\frac{\partial\,\phi_{nk}}{\partial\,a_{d\ell}}
=\delta_{\ell k}\,(1-\phi_{nk}^2)\,x_{nd}.
\]</div>
<p>This observation allows us to simplify the implementation, as in practice, we only need to keep track of the non-zero part of the Jacobian.</p>
<p>For each basis unit <span class="math notranslate nohighlight">\(k\)</span> you get the non-zero gradient</p>
<div class="math notranslate nohighlight">
\[
\nabla_{a_{\cdot k}}\phi_{\cdot k}
=\bigl(1-\phi_{\cdot k}^2\bigr)\odot x_{\cdot\,:\,}
\]</div>
<p>(where “<span class="math notranslate nohighlight">\(\odot\)</span>” is element-wise multiplication of the vector <span class="math notranslate nohighlight">\(1-\phi_{nk}^2\)</span> with each column of the design matrix).</p>
</section>
</section>
<section id="partial-derivative-for-the-weights-b-k">
<h2>Partial derivative for the weights <span class="math notranslate nohighlight">\(b_k\)</span><a class="headerlink" href="#partial-derivative-for-the-weights-b-k" title="Link to this heading">#</a></h2>
<p>The non-zero part of the Jacobian with respect to the bias <span class="math notranslate nohighlight">\(b_k\)</span> is a vector of size <span class="math notranslate nohighlight">\(N\)</span> (one for each data point) and is given by:</p>
<div class="math notranslate nohighlight">
\[
\frac{\partial\,\phi_{nk}}{\partial\,b_k}
=\frac{d}{dz}\tanh(z)\Big|_{z=z_{nk}}
=\frac{d}{dz}\tanh(z_{nk})
=1 - \tanh^2(z_{nk})
=1 - \phi_{nk}^2.
\]</div>
<p>This shows how the tanh function responds to changes in the bias hyperparameter <span class="math notranslate nohighlight">\(b_k\)</span>.</p>
<p>Let’s implement the tanh basis with a function <code class="docutils literal notranslate"><span class="pre">jacobian(X)</span></code> that returns the Jacobian matrix.</p>
<p>The returned Jacobian <code class="docutils literal notranslate"><span class="pre">J</span></code> has shape <span class="math notranslate nohighlight">\((N,\,D+1,\,k)\)</span> with</p>
<div class="math notranslate nohighlight">
\[\begin{split}
J[n,d,k] \;=\; \frac{\partial\,\phi_{n,k}}{\partial\,W_{d,k}}
\;=\;
\begin{cases}
(1-\phi_{n,k}^2)\,X_{n,d}, &amp; d&lt;D\quad(\text{zero-based indexing}),\\
(1-\phi_{n,k}^2), &amp; d=D\quad(\text{bias term}).
\end{cases}
\end{split}\]</div>
<p>Analytic derivations and implementations of Jacobians are always invovled and there are many ways to make errors.
To assert that the implementation is correct, we  added a <code class="docutils literal notranslate"><span class="pre">numerical_jacobian(X,</span> <span class="pre">eps)</span></code> method to the <code class="docutils literal notranslate"><span class="pre">TanhBasis</span></code> class. It perturbs each parameter <span class="math notranslate nohighlight">\(W_{d,k}\)</span> by <span class="math notranslate nohighlight">\(\pm\varepsilon\)</span>, recomputes the activations, and uses a central difference to numerically approximate</p>
<div class="math notranslate nohighlight">
\[
\frac{\partial \phi_{n,k}}{\partial W_{d,k}}
\equiv \frac{\phi_{n,k}(W_{d,k}+\varepsilon)\;-\;\phi_{n,k}(W_{d,k}-\varepsilon)}{2\varepsilon}.
\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="k">class</span><span class="w"> </span><span class="nc">TanhBasis</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">W</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        W: array of shape (D+1, P), where</span>
<span class="sd">        - W[:D, k] are the slopes a_dk for each input dimension d and unit k</span>
<span class="sd">        - W[D, k] is the bias b_k for unit k.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">W</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">Z</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute the product of the input data and the weights.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">X</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute the tanh basis functions.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Z</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">jacobian</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute the Jacobian of the tanh basis functions.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
        <span class="n">dZ_dW</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">))))</span> <span class="c1"># shape (N,D+1)</span>
        <span class="n">dPhi_dz</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Z</span><span class="p">(</span><span class="n">X</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>   <span class="c1"># shape (N,P)</span>
        <span class="k">return</span> <span class="n">dZ_dW</span><span class="p">[:,:,</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span> <span class="o">*</span> <span class="n">dPhi_dz</span><span class="p">[:,</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,:]</span> <span class="c1"># shape (N,D+1,P)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">numerical_jacobian</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Numerically approximate the Jacobian of transform(X) wrt W.</span>
<span class="sd">        Returns an array of shape (n, d+1, p).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">original_W</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">N</span><span class="p">,</span> <span class="n">D</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">K</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">num_J</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">D</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">K</span><span class="p">))</span>
        <span class="c1"># iterate over each parameter j,k</span>
        <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">D</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">):</span>
                <span class="c1"># perturb up</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">original_W</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">[</span><span class="n">d</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">+=</span> <span class="n">eps</span>
                <span class="n">phi_plus</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
                <span class="c1"># perturb down</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">original_W</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">[</span><span class="n">d</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">-=</span> <span class="n">eps</span>
                <span class="n">phi_minus</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
                <span class="c1"># central difference</span>
                <span class="n">num_J</span><span class="p">[:,</span> <span class="n">d</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">phi_plus</span><span class="p">[:,</span> <span class="n">k</span><span class="p">]</span> <span class="o">-</span> <span class="n">phi_minus</span><span class="p">[:,</span> <span class="n">k</span><span class="p">])</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">eps</span><span class="p">)</span>
        <span class="c1"># restore W</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">original_W</span>
        <span class="k">return</span> <span class="n">num_J</span>
</pre></div>
</div>
</div>
</div>
<p>A quick comparison on random data shows the max absolute difference between analytic and numeric Jacobians is on the order of <span class="math notranslate nohighlight">\(10^{-11}\)</span>, confirming that the analytic Jacobian is correctly implemented:</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>           <span class="c1"># 5 samples, 3 features</span>
<span class="n">W_init</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="mf">0.1</span>  <span class="c1"># 3 slopes + 1 bias, 2 units</span>
<span class="n">tanh_basis</span> <span class="o">=</span> <span class="n">TanhBasis</span><span class="p">(</span><span class="n">W_init</span><span class="p">)</span>

<span class="c1"># Analytical Jacobian</span>
<span class="n">J_analytic</span> <span class="o">=</span> <span class="n">tanh_basis</span><span class="o">.</span><span class="n">jacobian</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="c1"># Numerical Jacobian</span>
<span class="n">J_numeric</span>  <span class="o">=</span> <span class="n">tanh_basis</span><span class="o">.</span><span class="n">numerical_jacobian</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Max abs diff:&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">J_analytic</span> <span class="o">-</span> <span class="n">J_numeric</span><span class="p">)))</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Max abs diff: 3.4030778195415223e-11
</pre></div>
</div>
</div>
</div>
</section>
<hr class="docutils" />
<section id="visualizing-the-jacobian-of-tanh-basis-functions">
<h2><strong>Visualizing the Jacobian of Tanh Basis Functions</strong><a class="headerlink" href="#visualizing-the-jacobian-of-tanh-basis-functions" title="Link to this heading">#</a></h2>
<p>In the following, we visualize the three tanh basis functions that we used in the previous Section for temperature prediction and their Jacobians with respect to the slope <span class="math notranslate nohighlight">\(a\)</span>, and bias <span class="math notranslate nohighlight">\(b\)</span>.
We will plot the three tanh basis functions and their Jacobians with respect to the slope <span class="math notranslate nohighlight">\(a\)</span>, and bias <span class="math notranslate nohighlight">\(b\)</span>.</p>
<ol class="arabic simple">
<li><p><strong>∂φ/∂a</strong> (Jacobian w.r.t. the slope hyperparameter <span class="math notranslate nohighlight">\(a\)</span>) at a fixed 1-dimensional <span class="math notranslate nohighlight">\(x_0\)</span></p></li>
<li><p><strong>∂φ/∂b</strong> (Jacobian w.r.t. the bias hyperparameter <span class="math notranslate nohighlight">\(b\)</span>) at the same fixed 1-dimensional <span class="math notranslate nohighlight">\(x_0\)</span></p></li>
</ol>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="c1"># Basis parameters</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">.1</span><span class="p">,</span> <span class="mf">.2</span><span class="p">,</span> <span class="mf">.3</span><span class="p">])</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">10.0</span><span class="p">,</span><span class="o">-</span><span class="mf">50.0</span><span class="p">,</span><span class="o">-</span><span class="mf">100.0</span><span class="p">])</span>

<span class="c1"># tanh basis for single dimensional x and its derivatives</span>
<span class="k">def</span><span class="w"> </span><span class="nf">phi_tanh</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">a</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">dphi_tanh_da</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">a</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">dphi_tanh_db</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">a</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>

<span class="c1"># 1) Variation w.r.t. slope a at x0</span>
<span class="n">x0</span> <span class="o">=</span> <span class="mf">150.0</span>
<span class="n">a_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">400</span><span class="p">)</span>
<span class="n">Phi_a</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">phi_tanh</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">a_vals</span><span class="p">,</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">DPa</span>    <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">dphi_tanh_da</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">a_vals</span><span class="p">,</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># 2) Variation w.r.t. bias b at x0</span>
<span class="n">b_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">60</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">400</span><span class="p">)</span>
<span class="n">Phi_b</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">phi_tanh</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">b_vals</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">DPb</span>    <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">dphi_tanh_db</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">b_vals</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Plot</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>

<span class="c1"># Slope hyperparameter derivative</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">a_vals</span><span class="p">,</span> <span class="n">Phi_a</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;φ</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">(a)=tanh(a·</span><span class="si">{</span><span class="n">x0</span><span class="si">}</span><span class="s1">+</span><span class="si">{</span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">a_vals</span><span class="p">,</span> <span class="n">DPa</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span> <span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;∂φ</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">/∂a&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Variation w.r.t. slope a at x₀=</span><span class="si">{</span><span class="n">x0</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Variation w.r.t. slope a at x₀=</span><span class="si">{</span><span class="n">x0</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span> <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span> <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Bias hyperparameter derivative</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">b_vals</span><span class="p">,</span> <span class="n">Phi_b</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;φ</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">(b)=tanh(</span><span class="si">{</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s1">·</span><span class="si">{</span><span class="n">x0</span><span class="si">}</span><span class="s1">+b)&#39;</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">b_vals</span><span class="p">,</span> <span class="n">DPb</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span> <span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;∂φ</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">/∂b&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Variation w.r.t. bias b at x₀=</span><span class="si">{</span><span class="n">x0</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span> <span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Variation w.r.t. bias b at x₀=</span><span class="si">{</span><span class="n">x0</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span> <span class="n">axs</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../_images/5ce05e09527ad988583cf67571ba5eb44939f3bba42e660641b5f807da5fc731.png" src="../_images/5ce05e09527ad988583cf67571ba5eb44939f3bba42e660641b5f807da5fc731.png" />
</div>
</div>
<p>Before we can use the <code class="docutils literal notranslate"><span class="pre">TanhBasis</span></code> class with Jacobian to optimize over the hyperparameters in our ridge regression, we need to understand, how the Jacobian is used in the optimization process. The missing ingredient is the <strong>chain rule</strong> that we will discuss next.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chapter_calculus"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="matrix_calculus.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Matrix calculus</p>
      </div>
    </a>
    <a class="right-next"
       href="chain_rule.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">The chain rule</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#basis-functions-and-their-jacobians">Basis Functions and their Jacobians</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#jacobian-of-tanh-basis-functions">Jacobian of tanh basis functions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#partial-derivative-for-the-weights-a-kd">Partial derivative for the weights <span class="math notranslate nohighlight">\(a_{kd}\)</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#chain-rule-decomposition">1. Chain-rule decomposition</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#compute-each-factor">2. Compute each factor</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#put-it-together">3. Put it together</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#matrix-form-view">Matrix-form view</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#partial-derivative-for-the-weights-b-k">Partial derivative for the weights <span class="math notranslate nohighlight">\(b_k\)</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizing-the-jacobian-of-tanh-basis-functions"><strong>Visualizing the Jacobian of Tanh Basis Functions</strong></a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Christoph Lippert
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <script src="https://giscus.app/client.js"
        data-repo="HealthML/Math4ML"
        data-repo-id="R_kgDON-O79w"
        data-category="Comments"
        data-category-id="DIC_kwDON-O7984Co2qc"
        data-mapping="pathname"
        data-strict="1"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-input-position="top"
        data-theme="preferred_color_scheme"
        data-lang="en"
        data-loading="lazy"
        crossorigin="anonymous"
        async>
</script>

</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>