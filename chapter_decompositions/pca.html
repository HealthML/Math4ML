
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Principal Components Analysis &#8212; Mathematics for Machine Learning</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapter_decompositions/pca';</script>
    <link rel="canonical" href="https://healthml.github.io/Math4ML/chapter_decompositions/pca.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Singular value decomposition" href="svd.html" />
    <link rel="prev" title="Positive (semi-)definite matrices" href="psd_matrices.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/hpi-logo-colored.svg" class="logo__image only-light" alt="Mathematics for Machine Learning - Home"/>
    <script>document.write(`<img src="../_static/hpi-logo-colored.svg" class="logo__image only-dark" alt="Mathematics for Machine Learning - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    Preface
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Mathematics for Machine Learning</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_ml_basics/intro.html">Machine Learning Problems</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_ml_basics/classification.html">Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_ml_basics/regression.html">Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_ml_basics/clustering.html">Clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_ml_basics/representation_learning.html">Representation Learning</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_spaces/overview_spaces.html">Vector and Function Spaces</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_spaces/vector_spaces.html">Vector Spaces</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_spaces/polynomial_vector_space.html">Polynomial Vector Space</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_spaces/basis_functions_vector_space.html">Basis Functions Vector Space</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_spaces/subspaces.html">Subspaces</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_spaces/metric_spaces.html">Metric Spaces</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_spaces/normed_spaces.html">Normed Spaces</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_spaces/inner_product_spaces.html">Inner Product Spaces</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_spaces/transposition.html">Transposition</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_calculus/overview_calculus.html">Calculus and Optimization</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_calculus/extrema.html">Extrema</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_calculus/gradients.html">Gradients</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_calculus/gradient_descent_ridge.html">Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_calculus/matrix_calculus.html">Matrix Calculus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_calculus/jacobian.html">Jacobian</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_calculus/chain_rule.html">Chain Rule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_calculus/mean_value_theorem.html">Mean Value Theorem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_calculus/minima_first_order_condition.html">First Order Condition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_calculus/analytical_solution_ridge.html">Quadratic Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_calculus/line_search.html">Line Search</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_calculus/hessian.html">Hessian</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_calculus/taylors_theorem.html">Taylor’s Theorem</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="overview_decompositions.html">Matrix Analysis</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="matrix_rank.html">Rank of a Matrix</a></li>
<li class="toctree-l2"><a class="reference internal" href="determinant.html">Determinant</a></li>
<li class="toctree-l2"><a class="reference internal" href="row_equivalence.html">Gaussian Elimination and the PLU Decomposition</a></li>
<li class="toctree-l2"><a class="reference internal" href="square_matrices.html">Fundamental Equivalences for Square matrices</a></li>
<li class="toctree-l2"><a class="reference internal" href="trace.html">Trace</a></li>
<li class="toctree-l2"><a class="reference internal" href="eigenvectors.html">Eigenvalues and Eigenvectors</a></li>
<li class="toctree-l2"><a class="reference internal" href="orthogonal_matrices.html">Orthogonal matrices</a></li>
<li class="toctree-l2"><a class="reference internal" href="symmetric_matrices.html">Symmetric matrices</a></li>
<li class="toctree-l2"><a class="reference internal" href="Rayleigh_quotients.html">Rayleigh Quotients</a></li>
<li class="toctree-l2"><a class="reference internal" href="matrix_norms.html">Matrix Norms</a></li>
<li class="toctree-l2"><a class="reference internal" href="psd_matrices.html">Positive (semi-)definite matrices</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Principal Components Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="svd.html">Singular value decomposition</a></li>
<li class="toctree-l2"><a class="reference internal" href="pseudoinverse.html">Moore-Penrose Pseudoinverse</a></li>
<li class="toctree-l2"><a class="reference internal" href="orthogonal_projections.html">Orthogonal projections</a></li>
<li class="toctree-l2"><a class="reference internal" href="big_picture.html">Fundamental Subspaces</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_convexity/overview_convexity.html">Convexity</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convexity/convex_sets.html">Convex sets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convexity/convex_functions.html">Basics of convex functions</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_second_order/overview_second_order.html">Second-Order Optimization</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_second_order/minima_second_order_condition.html">Second Order Condition for Minima</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_second_order/newtons_method.html">Newton’s Method</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_probability/overview_probability.html">Probability</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_probability/probability_basics.html">Probability Basics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_probability/random_variables.html">Random variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_probability/expectation.html">Expected Value</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_probability/variance.html">Variance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_probability/covariance.html">Covariance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_probability/joint_distributions.html">Joint distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_probability/estimation.html">Estimation of Parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_probability/random_vectors.html">Random vectors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_probability/gaussian.html">The Gaussian distribution</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendix</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../appendix/proofs.html">Detailed Proofs</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../appendix/Cauchy%E2%80%93Schwarz_inequality.html">Cauchy-Schwarz Inequality</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix/Bolzano-Weierstrass_theorem.html">Bolzano-Weierstrass Theorem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix/extreme_value_theorem.html">Extreme Value Theorem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix/Rolles_theorem.html">Rolle's Theorem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix/mean_value_theorem_proof.html">Mean Value Theorem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix/scalar-scalar_chain_rule.html">Chain Rule for Scalar-Scalar Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix/squeeze_theorem.html">Squeeze Theorem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix/first_fundamental_theorem_calculus.html">First Fundamental Theorem of Calculus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix/second_fundamental_theorem_calculus.html">Second Fundamental Theorem of Calculus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix/Clairauts_theorem.html">Clairaut's Theorem</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../appendix/differentiation_rules.html">Differentiation Rules</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../appendix/Exercise%20Sheet%20Solutions.html">Exercise Sheet Solutions</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../appendix/Exercise%20Sheet%201%20Solutions.html">Exercise Sheet 1 Solutions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix/Exercise%20Sheet%202%20Solutions.html">Exercise Sheet 2 Solutions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix/Exercise%20Sheet%203%20Solutions.html">Exercise Sheet 3 Solutions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix/Exercise%20Sheet%204%20Solutions.html">Exercise Sheet 4 Solutions</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/HealthML/Math4ML" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/HealthML/Math4ML/edit/main/book/chapter_decompositions/pca.md" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/HealthML/Math4ML/issues/new?title=Issue%20on%20page%20%2Fchapter_decompositions/pca.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/chapter_decompositions/pca.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Principal Components Analysis</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#formal-definition">Formal definition</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-center-the-data">Step 1: Center the Data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-2-define-the-projection">Step 2: Define the Projection</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-3-define-the-reconstruction-error">Step 3: Define the Reconstruction Error</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4-reformulate-as-a-maximization-problem">Step 4: Reformulate as a Maximization Problem</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-5-solve-using-the-spectral-theorem">Step 5: Solve Using the Spectral Theorem</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pca-derivation-summary">PCA Derivation Summary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pca-algorithm-step-by-step">PCA algorithm step by step</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implementation">Implementation</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="principal-components-analysis">
<h1>Principal Components Analysis<a class="headerlink" href="#principal-components-analysis" title="Link to this heading">#</a></h1>
<p>Pricnipal Components Analysis (PCA) performs the orthogonal projection of the data onto a lower dimensional linear space. The goal is to find the directions (principal components) in which the variance of the data is maximized.
An alternative definition of PCA is based on minimizing the sum-of-sqares of the projection errors.</p>
<section id="formal-definition">
<h2>Formal definition<a class="headerlink" href="#formal-definition" title="Link to this heading">#</a></h2>
<p>Given a dataset <span class="math notranslate nohighlight">\(\mathbf{X} \in \mathbb{R}^{N \times D}\)</span> (rows are samples, columns are features), we aim to find an orthonormal basis <span class="math notranslate nohighlight">\(\mathbf{U}_k \in \mathbb{R}^{D \times k}\)</span>, <span class="math notranslate nohighlight">\(k &lt; D\)</span>, such that the projection of the data onto the subspace spanned by <span class="math notranslate nohighlight">\(\mathbf{U}_k\)</span> captures <strong>as much variance</strong> (energy) as possible.</p>
<p>In the following example, we visualize how PCA both minimizes reconstruction error in the original space and extracts a lower-dimensional, variance-preserving representation.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pysnptools.snpreader</span><span class="w"> </span><span class="kn">import</span> <span class="n">Bed</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mpl_toolkits.mplot3d</span><span class="w"> </span><span class="kn">import</span> <span class="n">Axes3D</span>

<span class="c1"># Generate synthetic 3D data</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">covariance_3d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
    <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">0.7</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>
<span class="p">])</span>
<span class="n">rotation_3d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">covariance_3d</span><span class="p">)</span>
<span class="n">data_3d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="o">@</span> <span class="n">rotation_3d</span><span class="o">.</span><span class="n">T</span>

<span class="c1"># Center the data</span>
<span class="n">mean_3d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">data_3d</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">data_centered_3d</span> <span class="o">=</span> <span class="n">data_3d</span> <span class="o">-</span> <span class="n">mean_3d</span>

<span class="c1"># Compute SVD</span>
<span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">Vt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">data_centered_3d</span><span class="p">,</span> <span class="n">full_matrices</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">V</span> <span class="o">=</span> <span class="n">Vt</span><span class="o">.</span><span class="n">T</span>
<span class="n">S2</span> <span class="o">=</span> <span class="n">S</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
<span class="n">V2</span> <span class="o">=</span> <span class="n">V</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span>

<span class="c1"># Project and reconstruct</span>
<span class="n">proj_2d</span> <span class="o">=</span> <span class="n">data_centered_3d</span> <span class="o">@</span> <span class="n">V2</span>
<span class="n">recon_3d</span> <span class="o">=</span> <span class="p">(</span><span class="n">proj_2d</span> <span class="o">@</span> <span class="n">V2</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">+</span> <span class="n">mean_3d</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:]</span>

<span class="c1"># Create a mesh grid for the 2D PCA plane</span>
<span class="n">grid_range</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">xx</span><span class="p">,</span> <span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">grid_range</span><span class="p">,</span> <span class="n">grid_range</span><span class="p">)</span>
<span class="n">plane_points</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">xx</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">yy</span><span class="o">.</span><span class="n">ravel</span><span class="p">()],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plane_points</span> <span class="o">*=</span> <span class="n">S2</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:]</span>
<span class="n">plane_3d</span> <span class="o">=</span> <span class="n">mean_3d</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:]</span> <span class="o">+</span> <span class="p">(</span><span class="n">plane_points</span> <span class="o">@</span> <span class="n">V2</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

<span class="c1"># Plot: 3D PCA + 2D Projection with principal components added in 2D view</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="c1"># 3D plot</span>
<span class="n">ax1</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s1">&#39;3d&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">data_3d</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">data_3d</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">data_3d</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Original Data&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">recon_3d</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">recon_3d</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">recon_3d</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Projected (Reconstructed) Points&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">):</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="p">[</span><span class="n">data_3d</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">recon_3d</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span>
        <span class="p">[</span><span class="n">data_3d</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">recon_3d</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span>
        <span class="p">[</span><span class="n">data_3d</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">recon_3d</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span>
        <span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span>
    <span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot_trisurf</span><span class="p">(</span><span class="n">plane_3d</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">plane_3d</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">plane_3d</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">)</span>
<span class="n">origin</span> <span class="o">=</span> <span class="n">mean_3d</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">quiver</span><span class="p">(</span><span class="o">*</span><span class="n">origin</span><span class="p">,</span> <span class="o">*</span><span class="n">V</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">S2</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">quiver</span><span class="p">(</span><span class="o">*</span><span class="n">origin</span><span class="p">,</span> <span class="o">*</span><span class="n">V</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">S2</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;PCA in 3D: Projection onto First Two PCs&quot;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_zlabel</span><span class="p">(</span><span class="s2">&quot;Z&quot;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="c1"># 2D projection plot</span>
<span class="n">ax2</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">proj_2d</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">proj_2d</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;2D Projection&#39;</span><span class="p">)</span>
<span class="c1"># draw PC directions</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="n">S2</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;1st PC&#39;</span><span class="p">)</span>  <span class="c1"># x-axis</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">S2</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">2</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;2nd PC&#39;</span><span class="p">)</span>  <span class="c1"># y-axis</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Data Projected onto First Two Principal Components&quot;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;1st PC&quot;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;2nd PC&quot;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../_images/cd66d7dd6747d58ff1aeaa9e35a04e8e08653bd0ead962177a7fe91ab51a7477.png" src="../_images/cd66d7dd6747d58ff1aeaa9e35a04e8e08653bd0ead962177a7fe91ab51a7477.png" />
</div>
</div>
<ul class="simple">
<li><p><strong>Left panel</strong>: The original 3D data, its projection onto the best-fit 2D PCA plane (orange), and reconstruction lines showing projection error.</p></li>
<li><p><strong>Right panel</strong>: The same data projected onto the first two principal components, visualized in 2D.</p></li>
</ul>
<section id="step-1-center-the-data">
<h3>Step 1: Center the Data<a class="headerlink" href="#step-1-center-the-data" title="Link to this heading">#</a></h3>
<p>We begin by centering the dataset so that the empirical mean is 0:</p>
<div class="math notranslate nohighlight">
\[
\bar{\mathbf{x}} = \frac{1}{N} \sum_{i=1}^N \mathbf{x}_i, \quad \mathbf{X}_{\text{centered}} = \mathbf{X} - \mathbf{1}_N \bar{\mathbf{x}}^\top
\]</div>
<p>Define <span class="math notranslate nohighlight">\(\mathbf{X} \leftarrow \mathbf{X}_{\text{centered}}\)</span> for the rest of the derivation.</p>
</section>
<hr class="docutils" />
<section id="step-2-define-the-projection">
<h3>Step 2: Define the Projection<a class="headerlink" href="#step-2-define-the-projection" title="Link to this heading">#</a></h3>
<p>Let <span class="math notranslate nohighlight">\(\mathbf{U}_k \in \mathbb{R}^{D \times k}\)</span> be an orthonormal matrix: <span class="math notranslate nohighlight">\(\mathbf{U}_k^\top \mathbf{U}_k = \mathbf{I}_k\)</span>.</p>
<p>Project each sample <span class="math notranslate nohighlight">\(\mathbf{x}_i \in \mathbb{R}^D\)</span> onto the subspace:</p>
<div class="math notranslate nohighlight">
\[
\mathbf{z}_i = \mathbf{U}_k^\top \mathbf{x}_i \quad \text{(coordinates in the new basis)}
\]</div>
<div class="math notranslate nohighlight">
\[
\hat{\mathbf{x}}_i = \mathbf{U}_k \mathbf{z}_i = \mathbf{U}_k \mathbf{U}_k^\top \mathbf{x}_i \quad \text{(projected vector)}
\]</div>
<p>The projection matrix is:</p>
<div class="math notranslate nohighlight">
\[
\mathbf{P} = \mathbf{U}_k \mathbf{U}_k^\top
\]</div>
</section>
<hr class="docutils" />
<section id="step-3-define-the-reconstruction-error">
<h3>Step 3: Define the Reconstruction Error<a class="headerlink" href="#step-3-define-the-reconstruction-error" title="Link to this heading">#</a></h3>
<p>We want to <strong>minimize</strong> the total squared reconstruction error (projection error):</p>
<div class="math notranslate nohighlight">
\[
\sum_{i=1}^N \left\| \mathbf{x}_i - \hat{\mathbf{x}}_i \right\|^2
= \sum_{i=1}^N \left\| \mathbf{x}_i - \mathbf{U}_k \mathbf{U}_k^\top \mathbf{x}_i \right\|^2
\]</div>
<p>In matrix form:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L}(\mathbf{U}_k) = \left\| \mathbf{X} - \mathbf{X} \mathbf{U}_k \mathbf{U}_k^\top \right\|_F^2
\]</div>
<p>where <span class="math notranslate nohighlight">\(\|\cdot\|_F\)</span> denotes the Frobenius norm.</p>
</section>
<hr class="docutils" />
<section id="step-4-reformulate-as-a-maximization-problem">
<h3>Step 4: Reformulate as a Maximization Problem<a class="headerlink" href="#step-4-reformulate-as-a-maximization-problem" title="Link to this heading">#</a></h3>
<p>Instead of minimizing reconstruction error, we <strong>maximize the variance (energy) retained</strong>:</p>
<div class="math notranslate nohighlight">
\[
\text{maximize } \text{tr}\left( \mathbf{U}_k^\top \mathbf{X}^\top \mathbf{X} \mathbf{U}_k \right) \quad \text{subject to } \mathbf{U}_k^\top \mathbf{U}_k = \mathbf{I}
\]</div>
<p>This comes from noting:</p>
<div class="math notranslate nohighlight">
\[
\|\mathbf{X} \mathbf{U}_k\|_F^2 = \sum_{i=1}^N \|\mathbf{U}_k^\top \mathbf{x}_i\|^2 = \text{tr}\left( \mathbf{U}_k^\top \mathbf{X}^\top \mathbf{X} \mathbf{U}_k \right)
\]</div>
</section>
<hr class="docutils" />
<section id="step-5-solve-using-the-spectral-theorem">
<h3>Step 5: Solve Using the Spectral Theorem<a class="headerlink" href="#step-5-solve-using-the-spectral-theorem" title="Link to this heading">#</a></h3>
<p>Let <span class="math notranslate nohighlight">\(\mathbf{X}^\top \mathbf{X} = \mathbf{M} \in \mathbb{R}^{D \times D}\)</span>. This matrix is symmetric and positive semidefinite.</p>
<p>By the <strong>spectral theorem</strong>, there exists an orthonormal basis of eigenvectors <span class="math notranslate nohighlight">\(\mathbf{u}_1, \dots, \mathbf{u}_D\)</span> with eigenvalues <span class="math notranslate nohighlight">\(\lambda_1 \ge \lambda_2 \ge \dots \ge \lambda_D \ge 0\)</span>, such that:</p>
<div class="math notranslate nohighlight">
\[
\mathbf{M} = \mathbf{X}^\top \mathbf{X} = \mathbf{U} \Lambda \mathbf{U}^\top
\]</div>
<p>Choose <span class="math notranslate nohighlight">\(\mathbf{U}_k = [\mathbf{u}_1, \dots, \mathbf{u}_k]\)</span> to maximize <span class="math notranslate nohighlight">\(\text{tr}( \mathbf{U}_k^\top \mathbf{M} \mathbf{U}_k )\)</span>.</p>
<p>This is optimal because trace is maximized by choosing eigenvectors with <strong>largest</strong> eigenvalues (known from Rayleigh-Ritz and Courant-Fischer principles).</p>
</section>
</section>
<section id="pca-derivation-summary">
<h2>PCA Derivation Summary<a class="headerlink" href="#pca-derivation-summary" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><strong>Input</strong>: Centered data matrix (\mathbf{X} \in \mathbb{R}^{N \times D})</p></li>
<li><p><strong>Goal</strong>: Find orthonormal matrix (\mathbf{U}_k \in \mathbb{R}^{D \times k}) that captures most variance</p></li>
<li><p><strong>Solution</strong>: Maximize ( \text{tr}(\mathbf{U}_k^\top \mathbf{X}^\top \mathbf{X} \mathbf{U}_k) ), subject to ( \mathbf{U}_k^\top \mathbf{U}_k = \mathbf{I} )</p></li>
<li><p><strong>Optimal</strong>: Columns of (\mathbf{U}_k) are top (k) eigenvectors of ( \mathbf{X}^\top \mathbf{X} )</p></li>
<li><p><strong>Projection</strong>: ( \mathbf{Z} = \mathbf{X} \mathbf{U}_k )</p></li>
<li><p><strong>Reconstruction</strong>: ( \tilde{\mathbf{X}} = \mathbf{Z} \mathbf{U}_k^\top )</p></li>
</ul>
</section>
<section id="pca-algorithm-step-by-step">
<h2>PCA algorithm step by step<a class="headerlink" href="#pca-algorithm-step-by-step" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Calculate the mean of the data</p></li>
</ol>
<div class="math notranslate nohighlight">
\[ \mathbf{\bar{x}} = \frac{1}{N} \sum_{i=1}^{N} \mathbf{x}_i \]</div>
<ol class="arabic simple" start="2">
<li><p>Calculate the covariance matrix <span class="math notranslate nohighlight">\(\mathbf{S}\)</span> of the data:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[ \mathbf{S} = \frac{1}{N-1} \sum_{i=1}^{N} (\mathbf{x}_i - \mathbf{\bar{x}})(\mathbf{x}_i - \mathbf{\bar{x}})^T \]</div>
<p>Both the mean and the covariance matrix are calculated by <code class="docutils literal notranslate"><span class="pre">empirical_covariance</span></code> function.</p>
<ol class="arabic simple" start="3">
<li><p>Calculate the eigenvalues <span class="math notranslate nohighlight">\(\lambda_i\)</span> and eigenvectors <span class="math notranslate nohighlight">\(\mathbf{u}_i\)</span> of the covariance matrix <span class="math notranslate nohighlight">\(\mathbf{S}\)</span></p></li>
<li><p>Sort the eigenvalues in descending order and then sort the eigenvectors accordingly.
Create a principal components matrix <span class="math notranslate nohighlight">\(\mathbf{U}\)</span> by taking the first <span class="math notranslate nohighlight">\(k\)</span> eigenvectors, where <span class="math notranslate nohighlight">\(k\)</span> is the number of dimensions we want to keep.
This step is implemented in the <code class="docutils literal notranslate"><span class="pre">fit</span></code> method of the <code class="docutils literal notranslate"><span class="pre">PCA</span></code> class.</p></li>
<li><p>To project the data onto the new space, we can use the following formula:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[ \mathbf{Y} = \mathbf{X} \cdot \mathbf{U} \]</div>
<p>This step is implemented in the <code class="docutils literal notranslate"><span class="pre">transform</span></code> method of the <code class="docutils literal notranslate"><span class="pre">PCA</span></code> class.</p>
<ol class="arabic simple" start="6">
<li><p>To reconstruct the data, we can use the following formula:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[ \mathbf{\tilde{X}} = \mathbf{Y} \cdot \mathbf{U}^T + \mathbf{\bar{x}} \]</div>
<p>This step is implemented in the <code class="docutils literal notranslate"><span class="pre">inverse_transform</span></code> method of the <code class="docutils literal notranslate"><span class="pre">PCA</span></code> class.</p>
<p>Note that recontructing the data will not give us the original data: <span class="math notranslate nohighlight">\(\mathbf{X} \neq \mathbf{\tilde{X}}\)</span>.</p>
</section>
<section id="implementation">
<h2>Implementation<a class="headerlink" href="#implementation" title="Link to this heading">#</a></h2>
<p>For the PCA algorithm we implement <code class="docutils literal notranslate"><span class="pre">empirical_covariance</span></code> method that would be usef do calculating the covariance of the data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">empirical_covariance</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates the empirical covariance matrix for a given dataset.</span>
<span class="sd">    </span>
<span class="sd">    Parameters:</span>
<span class="sd">    X (numpy.ndarray): A 2D numpy array where rows represent samples and columns represent features.</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">    tuple: A tuple containing the mean of the dataset and the covariance matrix.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">N</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># Number of samples</span>
    <span class="n">mean</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Calculate the mean of each feature</span>
    <span class="n">X_centered</span> <span class="o">=</span> <span class="n">X</span> <span class="o">-</span> <span class="n">mean</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:]</span>  <span class="c1"># Center the data by subtracting the mean</span>
    <span class="n">covariance</span> <span class="o">=</span> <span class="n">X_centered</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X_centered</span> <span class="o">/</span> <span class="p">(</span><span class="n">N</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># Compute the covariance matrix</span>
    <span class="k">return</span> <span class="n">mean</span><span class="p">,</span> <span class="n">covariance</span>
</pre></div>
</div>
</div>
</div>
<p>We also impmlement <code class="docutils literal notranslate"><span class="pre">PCA</span></code> class with <code class="docutils literal notranslate"><span class="pre">fit</span></code>, <code class="docutils literal notranslate"><span class="pre">transform</span></code> and <code class="docutils literal notranslate"><span class="pre">reverse_transform</span></code> methods.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">PCA</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes the PCA class without any components.</span>

<span class="sd">        Parameters:</span>
<span class="sd">        k (int, optional): Number of principal components to use.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pc_variances</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Eigenvalues of the covariance matrix</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">principal_components</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Eigenvectors of the covariance matrix</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Mean of the dataset</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">k</span>  <span class="c1"># the number of dimensions</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fit the PCA model to the dataset by computing the covariance matrix and its eigen decomposition.</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        X (numpy.ndarray): The data to fit the model on.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> <span class="n">covariance</span> <span class="o">=</span> <span class="n">empirical_covariance</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">)</span>
        <span class="n">eig_values</span><span class="p">,</span> <span class="n">eig_vectors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigh</span><span class="p">(</span><span class="n">covariance</span><span class="p">)</span>  <span class="c1"># Compute eigenvalues and eigenvectors</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pc_variances</span> <span class="o">=</span> <span class="n">eig_values</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># the eigenvalues are returned by eigh in ascending order. We want them in descending order (largest first)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">principal_components</span> <span class="o">=</span> <span class="n">eig_vectors</span><span class="p">[:,</span> <span class="p">::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># the eigenvectors in same order as eingevalues</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pc_variances</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pc_variances</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">principal_components</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">principal_components</span><span class="p">[:,:</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Transform the data into the principal component space.</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        X (numpy.ndarray): Data to transform.</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">        numpy.ndarray: Transformed data.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X_centered</span> <span class="o">=</span> <span class="n">X</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span>
        <span class="k">return</span> <span class="n">X_centered</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">principal_components</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">reverse_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Z</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Transform data back to its original space.</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        Z (numpy.ndarray): Transformed data to invert.</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">        numpy.ndarray: Data in its original space.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">Z</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">principal_components</span><span class="o">.</span><span class="n">T</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">variance_explained</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the amount of variance explained by the first k principal components.</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">        numpy.ndarray: Variances explained by the first k components.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">pc_variances</span>
</pre></div>
</div>
</div>
</div>
<p>In the example below, we will use the PCA algorithm to reduce the dimensionality of a genetic dataset from the 1000 genomes project [1,2].</p>
<p>[1] Auton, A. et al. A global reference for human genetic variation. Nature 526, 68–74 (2015)</p>
<p>[2] Altshuler, D. M. et al. Integrating common and rare genetic variation in diverse human populations. Nature 467, 52–58 (2010)</p>
<p>After reducing the dimensionality, we will plot the results and examine whether clusters of ancestries are visible.</p>
<p>We consider five ancestries in the dataset:</p>
<ul class="simple">
<li><p><strong>EUR</strong> - European</p></li>
<li><p><strong>AFR</strong> - African</p></li>
<li><p><strong>EAS</strong> - East Asian</p></li>
<li><p><strong>SAS</strong> - South Asian</p></li>
<li><p><strong>AMR</strong> - Native American</p></li>
</ul>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">snpreader</span> <span class="o">=</span> <span class="n">Bed</span><span class="p">(</span><span class="s1">&#39;../../datasets/genetic_data_1kg/example2.bed&#39;</span><span class="p">,</span> <span class="n">count_A1</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">snpreader</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="c1"># y includes our labels and x includes our features</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../../datasets/genetic_data_1kg/1kg_annotations_edit.txt&quot;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="s2">&quot;Sample&quot;</span><span class="p">)</span>
<span class="n">list1</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">iid</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>  <span class="c1">#list with the Sample numbers present in genetic dataset</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">labels</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">list1</span><span class="p">)]</span>  <span class="c1">#filter labels DataFrame so it only contains the sampleIDs present in genetic data</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">SuperPopulation</span>  <span class="c1"># EUR, AFR, AMR, EAS, SAS</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">val</span><span class="p">[:,</span> <span class="o">~</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">val</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)]</span>  <span class="c1">#load genetic data to X, removing NaN values</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">()</span>
<span class="n">pca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">)</span>

<span class="n">X_pc</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">X_reconstruction_full</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">reverse_transform</span><span class="p">(</span><span class="n">X_pc</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;L1 reconstruction error for full PCA : </span><span class="si">%.4E</span><span class="s2"> &quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">absolute</span><span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">X_reconstruction_full</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()))</span>

<span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>    <span class="c1">#more correct: X_pc.shape[1]+1</span>
    <span class="n">pca_lowrank</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="n">rank</span><span class="p">)</span>
    <span class="n">pca_lowrank</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">)</span>
    <span class="n">X_lowrank</span> <span class="o">=</span> <span class="n">pca_lowrank</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">X_reconstruction</span> <span class="o">=</span> <span class="n">pca_lowrank</span><span class="o">.</span><span class="n">reverse_transform</span><span class="p">(</span><span class="n">X_lowrank</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;L1 reconstruction error for rank </span><span class="si">%i</span><span class="s2"> PCA : </span><span class="si">%.4E</span><span class="s2"> &quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">absolute</span><span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">X_reconstruction</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()))</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_pc</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="s2">&quot;EUR&quot;</span><span class="p">][:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_pc</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="s2">&quot;EUR&quot;</span><span class="p">][:,</span><span class="mi">1</span><span class="p">],</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_pc</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="s2">&quot;AFR&quot;</span><span class="p">][:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_pc</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="s2">&quot;AFR&quot;</span><span class="p">][:,</span><span class="mi">1</span><span class="p">],</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_pc</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="s2">&quot;EAS&quot;</span><span class="p">][:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_pc</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="s2">&quot;EAS&quot;</span><span class="p">][:,</span><span class="mi">1</span><span class="p">],</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_pc</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="s2">&quot;AMR&quot;</span><span class="p">][:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_pc</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="s2">&quot;AMR&quot;</span><span class="p">][:,</span><span class="mi">1</span><span class="p">],</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_pc</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="s2">&quot;SAS&quot;</span><span class="p">][:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_pc</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="s2">&quot;SAS&quot;</span><span class="p">][:,</span><span class="mi">1</span><span class="p">],</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;PC 1&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;PC 2&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;EUR&quot;</span><span class="p">,</span> <span class="s2">&quot;AFR&quot;</span><span class="p">,</span><span class="s2">&quot;EAS&quot;</span><span class="p">,</span><span class="s2">&quot;AMR&quot;</span><span class="p">,</span><span class="s2">&quot;SAS&quot;</span><span class="p">])</span>

<span class="n">fig2</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_pc</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="s2">&quot;EUR&quot;</span><span class="p">][:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_pc</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="s2">&quot;EUR&quot;</span><span class="p">][:,</span><span class="mi">2</span><span class="p">],</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_pc</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="s2">&quot;AFR&quot;</span><span class="p">][:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_pc</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="s2">&quot;AFR&quot;</span><span class="p">][:,</span><span class="mi">2</span><span class="p">],</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_pc</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="s2">&quot;EAS&quot;</span><span class="p">][:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_pc</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="s2">&quot;EAS&quot;</span><span class="p">][:,</span><span class="mi">2</span><span class="p">],</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_pc</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="s2">&quot;AMR&quot;</span><span class="p">][:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_pc</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="s2">&quot;AMR&quot;</span><span class="p">][:,</span><span class="mi">2</span><span class="p">],</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_pc</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="s2">&quot;SAS&quot;</span><span class="p">][:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_pc</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="s2">&quot;SAS&quot;</span><span class="p">][:,</span><span class="mi">2</span><span class="p">],</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;PC 1&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;PC 3&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;EUR&quot;</span><span class="p">,</span> <span class="s2">&quot;AFR&quot;</span><span class="p">,</span><span class="s2">&quot;EAS&quot;</span><span class="p">,</span><span class="s2">&quot;AMR&quot;</span><span class="p">,</span><span class="s2">&quot;SAS&quot;</span><span class="p">])</span>


<span class="n">fig3</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_pc</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="s2">&quot;EUR&quot;</span><span class="p">][:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">X_pc</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="s2">&quot;EUR&quot;</span><span class="p">][:,</span><span class="mi">2</span><span class="p">],</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_pc</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="s2">&quot;AFR&quot;</span><span class="p">][:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">X_pc</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="s2">&quot;AFR&quot;</span><span class="p">][:,</span><span class="mi">2</span><span class="p">],</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_pc</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="s2">&quot;EAS&quot;</span><span class="p">][:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">X_pc</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="s2">&quot;EAS&quot;</span><span class="p">][:,</span><span class="mi">2</span><span class="p">],</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_pc</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="s2">&quot;AMR&quot;</span><span class="p">][:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">X_pc</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="s2">&quot;AMR&quot;</span><span class="p">][:,</span><span class="mi">2</span><span class="p">],</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_pc</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="s2">&quot;SAS&quot;</span><span class="p">][:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">X_pc</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="s2">&quot;SAS&quot;</span><span class="p">][:,</span><span class="mi">2</span><span class="p">],</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;PC 2&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;PC 3&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;EUR&quot;</span><span class="p">,</span> <span class="s2">&quot;AFR&quot;</span><span class="p">,</span><span class="s2">&quot;EAS&quot;</span><span class="p">,</span><span class="s2">&quot;AMR&quot;</span><span class="p">,</span><span class="s2">&quot;SAS&quot;</span><span class="p">])</span>

<span class="n">fig4</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">variance_explained</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;PC dimension&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;variance explained&quot;</span><span class="p">)</span>

<span class="n">fig4</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">variance_explained</span><span class="p">()</span><span class="o">.</span><span class="n">cumsum</span><span class="p">()</span> <span class="o">/</span> <span class="n">pca</span><span class="o">.</span><span class="n">variance_explained</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;PC dimension&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;cumulative fraction of variance explained&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(267, 10626)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>L1 reconstruction error for full PCA : 1.3924E-09 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>L1 reconstruction error for rank 0 PCA : 3.7316E+05 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>L1 reconstruction error for rank 1 PCA : 3.4989E+05 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>L1 reconstruction error for rank 2 PCA : 3.3704E+05 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>L1 reconstruction error for rank 3 PCA : 3.3322E+05 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>L1 reconstruction error for rank 4 PCA : 3.3049E+05 
</pre></div>
</div>
<img alt="../_images/5dc0c1c3d0a3c2c9b14ec4dbe1633b0af5eb754a380ce68c37f06ed182921a7f.png" src="../_images/5dc0c1c3d0a3c2c9b14ec4dbe1633b0af5eb754a380ce68c37f06ed182921a7f.png" />
<img alt="../_images/72b07d27bff1c0cadef62d9937206c2d31089e066ac82752a7d940246c72d315.png" src="../_images/72b07d27bff1c0cadef62d9937206c2d31089e066ac82752a7d940246c72d315.png" />
<img alt="../_images/8b68ff04fde324a3f71c3f0e025c6809d5d523525dbecd38f74b96b078a603f4.png" src="../_images/8b68ff04fde324a3f71c3f0e025c6809d5d523525dbecd38f74b96b078a603f4.png" />
<img alt="../_images/8547435c4e04061dd9e829dad782037ab0029fb0a902d39b01bedad662c12f5e.png" src="../_images/8547435c4e04061dd9e829dad782037ab0029fb0a902d39b01bedad662c12f5e.png" />
<img alt="../_images/f5fb83d76c068ee828dd105c6c403904e31dabd65a855f426b8f0166ed7fe35a.png" src="../_images/f5fb83d76c068ee828dd105c6c403904e31dabd65a855f426b8f0166ed7fe35a.png" />
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chapter_decompositions"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="psd_matrices.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Positive (semi-)definite matrices</p>
      </div>
    </a>
    <a class="right-next"
       href="svd.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Singular value decomposition</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#formal-definition">Formal definition</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-center-the-data">Step 1: Center the Data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-2-define-the-projection">Step 2: Define the Projection</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-3-define-the-reconstruction-error">Step 3: Define the Reconstruction Error</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4-reformulate-as-a-maximization-problem">Step 4: Reformulate as a Maximization Problem</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-5-solve-using-the-spectral-theorem">Step 5: Solve Using the Spectral Theorem</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pca-derivation-summary">PCA Derivation Summary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pca-algorithm-step-by-step">PCA algorithm step by step</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implementation">Implementation</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Christoph Lippert
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <script src="https://giscus.app/client.js"
        data-repo="HealthML/Math4ML"
        data-repo-id="R_kgDON-O79w"
        data-category="Comments"
        data-category-id="DIC_kwDON-O7984Co2qc"
        data-mapping="pathname"
        data-strict="1"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-input-position="top"
        data-theme="preferred_color_scheme"
        data-lang="en"
        data-loading="lazy"
        crossorigin="anonymous"
        async>
</script>

</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>